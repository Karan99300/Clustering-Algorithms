{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0      14.23        1.71  2.43          15.6        127           2.80   \n",
       "1      13.20        1.78  2.14          11.2        100           2.65   \n",
       "2      13.16        2.36  2.67          18.6        101           2.80   \n",
       "3      14.37        1.95  2.50          16.8        113           3.85   \n",
       "4      13.24        2.59  2.87          21.0        118           2.80   \n",
       "..       ...         ...   ...           ...        ...            ...   \n",
       "173    13.71        5.65  2.45          20.5         95           1.68   \n",
       "174    13.40        3.91  2.48          23.0        102           1.80   \n",
       "175    13.27        4.28  2.26          20.0        120           1.59   \n",
       "176    13.17        2.59  2.37          20.0        120           1.65   \n",
       "177    14.13        4.10  2.74          24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     OD280  Proline  \n",
       "0     3.92     1065  \n",
       "1     3.40     1050  \n",
       "2     3.17     1185  \n",
       "3     3.45     1480  \n",
       "4     2.93      735  \n",
       "..     ...      ...  \n",
       "173   1.74      740  \n",
       "174   1.56      750  \n",
       "175   1.56      835  \n",
       "176   1.62      840  \n",
       "177   1.60      560  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\KARAN\\Desktop\\BBS Sir Proj\\wine-clustering.csv',encoding='unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "## we will do the splitting using a random state to ensure same splitting every time\n",
    "X_train, X_test = train_test_split(df.values,test_size = .3,random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02],\n",
       "       [1.156e+01, 2.050e+00, 3.230e+00, ..., 9.300e-01, 3.690e+00,\n",
       "        4.650e+02],\n",
       "       [1.438e+01, 1.870e+00, 2.380e+00, ..., 1.200e+00, 3.000e+00,\n",
       "        1.547e+03],\n",
       "       ...,\n",
       "       [1.196e+01, 1.090e+00, 2.300e+00, ..., 9.900e-01, 3.130e+00,\n",
       "        8.860e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.208e+01, 1.130e+00, 2.510e+00, ..., 1.310e+00, 2.720e+00,\n",
       "        6.300e+02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.316000e+01, 3.570000e+00, 2.150000e+00, 2.100000e+01,\n",
       "        1.020000e+02, 1.500000e+00, 5.500000e-01, 4.300000e-01,\n",
       "        1.300000e+00, 4.000000e+00, 6.000000e-01, 1.680000e+00,\n",
       "        8.300000e+02],\n",
       "       [1.406000e+01, 2.150000e+00, 2.610000e+00, 1.760000e+01,\n",
       "        1.210000e+02, 2.600000e+00, 2.510000e+00, 3.100000e-01,\n",
       "        1.250000e+00, 5.050000e+00, 1.060000e+00, 3.580000e+00,\n",
       "        1.295000e+03],\n",
       "       [1.350000e+01, 3.120000e+00, 2.620000e+00, 2.400000e+01,\n",
       "        1.230000e+02, 1.400000e+00, 1.570000e+00, 2.200000e-01,\n",
       "        1.250000e+00, 8.600000e+00, 5.900000e-01, 1.300000e+00,\n",
       "        5.000000e+02],\n",
       "       [1.146000e+01, 3.740000e+00, 1.820000e+00, 1.950000e+01,\n",
       "        1.070000e+02, 3.180000e+00, 2.580000e+00, 2.400000e-01,\n",
       "        3.580000e+00, 2.900000e+00, 7.500000e-01, 2.810000e+00,\n",
       "        5.620000e+02],\n",
       "       [1.251000e+01, 1.730000e+00, 1.980000e+00, 2.050000e+01,\n",
       "        8.500000e+01, 2.200000e+00, 1.920000e+00, 3.200000e-01,\n",
       "        1.480000e+00, 2.940000e+00, 1.040000e+00, 3.570000e+00,\n",
       "        6.720000e+02],\n",
       "       [1.165000e+01, 1.670000e+00, 2.620000e+00, 2.600000e+01,\n",
       "        8.800000e+01, 1.920000e+00, 1.610000e+00, 4.000000e-01,\n",
       "        1.340000e+00, 2.600000e+00, 1.360000e+00, 3.210000e+00,\n",
       "        5.620000e+02],\n",
       "       [1.348000e+01, 1.670000e+00, 2.640000e+00, 2.250000e+01,\n",
       "        8.900000e+01, 2.600000e+00, 1.100000e+00, 5.200000e-01,\n",
       "        2.290000e+00, 1.175000e+01, 5.700000e-01, 1.780000e+00,\n",
       "        6.200000e+02],\n",
       "       [1.305000e+01, 1.770000e+00, 2.100000e+00, 1.700000e+01,\n",
       "        1.070000e+02, 3.000000e+00, 3.000000e+00, 2.800000e-01,\n",
       "        2.030000e+00, 5.040000e+00, 8.800000e-01, 3.350000e+00,\n",
       "        8.850000e+02],\n",
       "       [1.208000e+01, 1.330000e+00, 2.300000e+00, 2.360000e+01,\n",
       "        7.000000e+01, 2.200000e+00, 1.590000e+00, 4.200000e-01,\n",
       "        1.380000e+00, 1.740000e+00, 1.070000e+00, 3.210000e+00,\n",
       "        6.250000e+02],\n",
       "       [1.217000e+01, 1.450000e+00, 2.530000e+00, 1.900000e+01,\n",
       "        1.040000e+02, 1.890000e+00, 1.750000e+00, 4.500000e-01,\n",
       "        1.030000e+00, 2.950000e+00, 1.450000e+00, 2.230000e+00,\n",
       "        3.550000e+02],\n",
       "       [1.410000e+01, 2.160000e+00, 2.300000e+00, 1.800000e+01,\n",
       "        1.050000e+02, 2.950000e+00, 3.320000e+00, 2.200000e-01,\n",
       "        2.380000e+00, 5.750000e+00, 1.250000e+00, 3.170000e+00,\n",
       "        1.510000e+03],\n",
       "       [1.388000e+01, 1.890000e+00, 2.590000e+00, 1.500000e+01,\n",
       "        1.010000e+02, 3.250000e+00, 3.560000e+00, 1.700000e-01,\n",
       "        1.700000e+00, 5.430000e+00, 8.800000e-01, 3.560000e+00,\n",
       "        1.095000e+03],\n",
       "       [1.277000e+01, 2.390000e+00, 2.280000e+00, 1.950000e+01,\n",
       "        8.600000e+01, 1.390000e+00, 5.100000e-01, 4.800000e-01,\n",
       "        6.400000e-01, 9.899999e+00, 5.700000e-01, 1.630000e+00,\n",
       "        4.700000e+02],\n",
       "       [1.200000e+01, 3.430000e+00, 2.000000e+00, 1.900000e+01,\n",
       "        8.700000e+01, 2.000000e+00, 1.640000e+00, 3.700000e-01,\n",
       "        1.870000e+00, 1.280000e+00, 9.300000e-01, 3.050000e+00,\n",
       "        5.640000e+02],\n",
       "       [1.371000e+01, 5.650000e+00, 2.450000e+00, 2.050000e+01,\n",
       "        9.500000e+01, 1.680000e+00, 6.100000e-01, 5.200000e-01,\n",
       "        1.060000e+00, 7.700000e+00, 6.400000e-01, 1.740000e+00,\n",
       "        7.400000e+02],\n",
       "       [1.233000e+01, 9.900000e-01, 1.950000e+00, 1.480000e+01,\n",
       "        1.360000e+02, 1.900000e+00, 1.850000e+00, 3.500000e-01,\n",
       "        2.760000e+00, 3.400000e+00, 1.060000e+00, 2.310000e+00,\n",
       "        7.500000e+02],\n",
       "       [1.208000e+01, 1.390000e+00, 2.500000e+00, 2.250000e+01,\n",
       "        8.400000e+01, 2.560000e+00, 2.290000e+00, 4.300000e-01,\n",
       "        1.040000e+00, 2.900000e+00, 9.300000e-01, 3.190000e+00,\n",
       "        3.850000e+02],\n",
       "       [1.363000e+01, 1.810000e+00, 2.700000e+00, 1.720000e+01,\n",
       "        1.120000e+02, 2.850000e+00, 2.910000e+00, 3.000000e-01,\n",
       "        1.460000e+00, 7.300000e+00, 1.280000e+00, 2.880000e+00,\n",
       "        1.310000e+03],\n",
       "       [1.285000e+01, 1.600000e+00, 2.520000e+00, 1.780000e+01,\n",
       "        9.500000e+01, 2.480000e+00, 2.370000e+00, 2.600000e-01,\n",
       "        1.460000e+00, 3.930000e+00, 1.090000e+00, 3.630000e+00,\n",
       "        1.015000e+03],\n",
       "       [1.334000e+01, 9.400000e-01, 2.360000e+00, 1.700000e+01,\n",
       "        1.100000e+02, 2.530000e+00, 1.300000e+00, 5.500000e-01,\n",
       "        4.200000e-01, 3.170000e+00, 1.020000e+00, 1.930000e+00,\n",
       "        7.500000e+02],\n",
       "       [1.286000e+01, 1.350000e+00, 2.320000e+00, 1.800000e+01,\n",
       "        1.220000e+02, 1.510000e+00, 1.250000e+00, 2.100000e-01,\n",
       "        9.400000e-01, 4.100000e+00, 7.600000e-01, 1.290000e+00,\n",
       "        6.300000e+02],\n",
       "       [1.237000e+01, 1.630000e+00, 2.300000e+00, 2.450000e+01,\n",
       "        8.800000e+01, 2.220000e+00, 2.450000e+00, 4.000000e-01,\n",
       "        1.900000e+00, 2.120000e+00, 8.900000e-01, 2.780000e+00,\n",
       "        3.420000e+02],\n",
       "       [1.383000e+01, 1.650000e+00, 2.600000e+00, 1.720000e+01,\n",
       "        9.400000e+01, 2.450000e+00, 2.990000e+00, 2.200000e-01,\n",
       "        2.290000e+00, 5.600000e+00, 1.240000e+00, 3.370000e+00,\n",
       "        1.265000e+03],\n",
       "       [1.376000e+01, 1.530000e+00, 2.700000e+00, 1.950000e+01,\n",
       "        1.320000e+02, 2.950000e+00, 2.740000e+00, 5.000000e-01,\n",
       "        1.350000e+00, 5.400000e+00, 1.250000e+00, 3.000000e+00,\n",
       "        1.235000e+03],\n",
       "       [1.317000e+01, 5.190000e+00, 2.320000e+00, 2.200000e+01,\n",
       "        9.300000e+01, 1.740000e+00, 6.300000e-01, 6.100000e-01,\n",
       "        1.550000e+00, 7.900000e+00, 6.000000e-01, 1.480000e+00,\n",
       "        7.250000e+02],\n",
       "       [1.184000e+01, 8.900000e-01, 2.580000e+00, 1.800000e+01,\n",
       "        9.400000e+01, 2.200000e+00, 2.210000e+00, 2.200000e-01,\n",
       "        2.350000e+00, 3.050000e+00, 7.900000e-01, 3.080000e+00,\n",
       "        5.200000e+02],\n",
       "       [1.311000e+01, 1.900000e+00, 2.750000e+00, 2.550000e+01,\n",
       "        1.160000e+02, 2.200000e+00, 1.280000e+00, 2.600000e-01,\n",
       "        1.560000e+00, 7.100000e+00, 6.100000e-01, 1.330000e+00,\n",
       "        4.250000e+02],\n",
       "       [1.187000e+01, 4.310000e+00, 2.390000e+00, 2.100000e+01,\n",
       "        8.200000e+01, 2.860000e+00, 3.030000e+00, 2.100000e-01,\n",
       "        2.910000e+00, 2.800000e+00, 7.500000e-01, 3.640000e+00,\n",
       "        3.800000e+02],\n",
       "       [1.375000e+01, 1.730000e+00, 2.410000e+00, 1.600000e+01,\n",
       "        8.900000e+01, 2.600000e+00, 2.760000e+00, 2.900000e-01,\n",
       "        1.810000e+00, 5.600000e+00, 1.150000e+00, 2.900000e+00,\n",
       "        1.320000e+03],\n",
       "       [1.340000e+01, 4.600000e+00, 2.860000e+00, 2.500000e+01,\n",
       "        1.120000e+02, 1.980000e+00, 9.600000e-01, 2.700000e-01,\n",
       "        1.110000e+00, 8.500000e+00, 6.700000e-01, 1.920000e+00,\n",
       "        6.300000e+02],\n",
       "       [1.222000e+01, 1.290000e+00, 1.940000e+00, 1.900000e+01,\n",
       "        9.200000e+01, 2.360000e+00, 2.040000e+00, 3.900000e-01,\n",
       "        2.080000e+00, 2.700000e+00, 8.600000e-01, 3.020000e+00,\n",
       "        3.120000e+02],\n",
       "       [1.242000e+01, 2.550000e+00, 2.270000e+00, 2.200000e+01,\n",
       "        9.000000e+01, 1.680000e+00, 1.840000e+00, 6.600000e-01,\n",
       "        1.420000e+00, 2.700000e+00, 8.600000e-01, 3.300000e+00,\n",
       "        3.150000e+02],\n",
       "       [1.419000e+01, 1.590000e+00, 2.480000e+00, 1.650000e+01,\n",
       "        1.080000e+02, 3.300000e+00, 3.930000e+00, 3.200000e-01,\n",
       "        1.860000e+00, 8.700000e+00, 1.230000e+00, 2.820000e+00,\n",
       "        1.680000e+03],\n",
       "       [1.200000e+01, 9.200000e-01, 2.000000e+00, 1.900000e+01,\n",
       "        8.600000e+01, 2.420000e+00, 2.260000e+00, 3.000000e-01,\n",
       "        1.430000e+00, 2.500000e+00, 1.380000e+00, 3.120000e+00,\n",
       "        2.780000e+02],\n",
       "       [1.368000e+01, 1.830000e+00, 2.360000e+00, 1.720000e+01,\n",
       "        1.040000e+02, 2.420000e+00, 2.690000e+00, 4.200000e-01,\n",
       "        1.970000e+00, 3.840000e+00, 1.230000e+00, 2.870000e+00,\n",
       "        9.900000e+02],\n",
       "       [1.364000e+01, 3.100000e+00, 2.560000e+00, 1.520000e+01,\n",
       "        1.160000e+02, 2.700000e+00, 3.030000e+00, 1.700000e-01,\n",
       "        1.660000e+00, 5.100000e+00, 9.600000e-01, 3.360000e+00,\n",
       "        8.450000e+02],\n",
       "       [1.383000e+01, 1.570000e+00, 2.620000e+00, 2.000000e+01,\n",
       "        1.150000e+02, 2.950000e+00, 3.400000e+00, 4.000000e-01,\n",
       "        1.720000e+00, 6.600000e+00, 1.130000e+00, 2.570000e+00,\n",
       "        1.130000e+03],\n",
       "       [1.285000e+01, 3.270000e+00, 2.580000e+00, 2.200000e+01,\n",
       "        1.060000e+02, 1.650000e+00, 6.000000e-01, 6.000000e-01,\n",
       "        9.600000e-01, 5.580000e+00, 8.700000e-01, 2.110000e+00,\n",
       "        5.700000e+02],\n",
       "       [1.260000e+01, 1.340000e+00, 1.900000e+00, 1.850000e+01,\n",
       "        8.800000e+01, 1.450000e+00, 1.360000e+00, 2.900000e-01,\n",
       "        1.350000e+00, 2.450000e+00, 1.040000e+00, 2.770000e+00,\n",
       "        5.620000e+02],\n",
       "       [1.251000e+01, 1.240000e+00, 2.250000e+00, 1.750000e+01,\n",
       "        8.500000e+01, 2.000000e+00, 5.800000e-01, 6.000000e-01,\n",
       "        1.250000e+00, 5.450000e+00, 7.500000e-01, 1.510000e+00,\n",
       "        6.500000e+02],\n",
       "       [1.269000e+01, 1.530000e+00, 2.260000e+00, 2.070000e+01,\n",
       "        8.000000e+01, 1.380000e+00, 1.460000e+00, 5.800000e-01,\n",
       "        1.620000e+00, 3.050000e+00, 9.600000e-01, 2.060000e+00,\n",
       "        4.950000e+02],\n",
       "       [1.369000e+01, 3.260000e+00, 2.540000e+00, 2.000000e+01,\n",
       "        1.070000e+02, 1.830000e+00, 5.600000e-01, 5.000000e-01,\n",
       "        8.000000e-01, 5.880000e+00, 9.600000e-01, 1.820000e+00,\n",
       "        6.800000e+02],\n",
       "       [1.247000e+01, 1.520000e+00, 2.200000e+00, 1.900000e+01,\n",
       "        1.620000e+02, 2.500000e+00, 2.270000e+00, 3.200000e-01,\n",
       "        3.280000e+00, 2.600000e+00, 1.160000e+00, 2.630000e+00,\n",
       "        9.370000e+02],\n",
       "       [1.207000e+01, 2.160000e+00, 2.170000e+00, 2.100000e+01,\n",
       "        8.500000e+01, 2.600000e+00, 2.650000e+00, 3.700000e-01,\n",
       "        1.350000e+00, 2.760000e+00, 8.600000e-01, 3.280000e+00,\n",
       "        3.780000e+02],\n",
       "       [1.293000e+01, 3.800000e+00, 2.650000e+00, 1.860000e+01,\n",
       "        1.020000e+02, 2.410000e+00, 2.410000e+00, 2.500000e-01,\n",
       "        1.980000e+00, 4.500000e+00, 1.030000e+00, 3.520000e+00,\n",
       "        7.700000e+02],\n",
       "       [1.438000e+01, 3.590000e+00, 2.280000e+00, 1.600000e+01,\n",
       "        1.020000e+02, 3.250000e+00, 3.170000e+00, 2.700000e-01,\n",
       "        2.190000e+00, 4.900000e+00, 1.040000e+00, 3.440000e+00,\n",
       "        1.065000e+03],\n",
       "       [1.272000e+01, 1.750000e+00, 2.280000e+00, 2.250000e+01,\n",
       "        8.400000e+01, 1.380000e+00, 1.760000e+00, 4.800000e-01,\n",
       "        1.630000e+00, 3.300000e+00, 8.800000e-01, 2.420000e+00,\n",
       "        4.880000e+02],\n",
       "       [1.483000e+01, 1.640000e+00, 2.170000e+00, 1.400000e+01,\n",
       "        9.700000e+01, 2.800000e+00, 2.980000e+00, 2.900000e-01,\n",
       "        1.980000e+00, 5.200000e+00, 1.080000e+00, 2.850000e+00,\n",
       "        1.045000e+03],\n",
       "       [1.208000e+01, 1.830000e+00, 2.320000e+00, 1.850000e+01,\n",
       "        8.100000e+01, 1.600000e+00, 1.500000e+00, 5.200000e-01,\n",
       "        1.640000e+00, 2.400000e+00, 1.080000e+00, 2.270000e+00,\n",
       "        4.800000e+02],\n",
       "       [1.229000e+01, 1.610000e+00, 2.210000e+00, 2.040000e+01,\n",
       "        1.030000e+02, 1.100000e+00, 1.020000e+00, 3.700000e-01,\n",
       "        1.460000e+00, 3.050000e+00, 9.060000e-01, 1.820000e+00,\n",
       "        8.700000e+02],\n",
       "       [1.225000e+01, 3.880000e+00, 2.200000e+00, 1.850000e+01,\n",
       "        1.120000e+02, 1.380000e+00, 7.800000e-01, 2.900000e-01,\n",
       "        1.140000e+00, 8.210000e+00, 6.500000e-01, 2.000000e+00,\n",
       "        8.550000e+02],\n",
       "       [1.373000e+01, 1.500000e+00, 2.700000e+00, 2.250000e+01,\n",
       "        1.010000e+02, 3.000000e+00, 3.250000e+00, 2.900000e-01,\n",
       "        2.380000e+00, 5.700000e+00, 1.190000e+00, 2.710000e+00,\n",
       "        1.285000e+03],\n",
       "       [1.270000e+01, 3.870000e+00, 2.400000e+00, 2.300000e+01,\n",
       "        1.010000e+02, 2.830000e+00, 2.550000e+00, 4.300000e-01,\n",
       "        1.950000e+00, 2.570000e+00, 1.190000e+00, 3.130000e+00,\n",
       "        4.630000e+02],\n",
       "       [1.307000e+01, 1.500000e+00, 2.100000e+00, 1.550000e+01,\n",
       "        9.800000e+01, 2.400000e+00, 2.640000e+00, 2.800000e-01,\n",
       "        1.370000e+00, 3.700000e+00, 1.180000e+00, 2.690000e+00,\n",
       "        1.020000e+03]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor_train = torch.FloatTensor(X_train).to(device)\n",
    "tensor_test=torch.FloatTensor(X_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autoencoder import Autoencoder\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "inputs_dim=df.shape[1]\n",
    "n_bottleneck=10\n",
    "model=Autoencoder(inputs_dim,n_bottleneck).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "train_loader = DataLoader(TensorDataset(tensor_train, tensor_train), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(tensor_test, tensor_test), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 - Training: 100%|██████████| 2/2 [00:02<00:00,  1.35s/batch, loss=50121.17188]\n",
      "Epoch 1/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 151.81batch/s, loss=54009.33984]\n",
      "Epoch 2/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 117.26batch/s, loss=49876.97852]\n",
      "Epoch 2/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 402.56batch/s, loss=53630.94531]\n",
      "Epoch 3/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.13batch/s, loss=49520.08594]\n",
      "Epoch 3/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 235.85batch/s, loss=53003.40625]\n",
      "Epoch 4/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.68batch/s, loss=48766.72852]\n",
      "Epoch 4/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=52119.95312]\n",
      "Epoch 5/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 146.92batch/s, loss=48030.17969]\n",
      "Epoch 5/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=50923.05469]\n",
      "Epoch 6/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 126.96batch/s, loss=46733.41406]\n",
      "Epoch 6/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 151.74batch/s, loss=49325.68750]\n",
      "Epoch 7/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.34batch/s, loss=45163.24805]\n",
      "Epoch 7/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 665.23batch/s, loss=47258.75000]\n",
      "Epoch 8/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 162.10batch/s, loss=43164.65625]\n",
      "Epoch 8/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=44610.18359]\n",
      "Epoch 9/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.51batch/s, loss=40530.89844]\n",
      "Epoch 9/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 697.89batch/s, loss=41239.88672]\n",
      "Epoch 10/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.66batch/s, loss=37239.42773]\n",
      "Epoch 10/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=37044.24609]\n",
      "Epoch 11/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.18batch/s, loss=33148.18652]\n",
      "Epoch 11/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 372.50batch/s, loss=31963.29688]\n",
      "Epoch 12/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.44batch/s, loss=28219.24512]\n",
      "Epoch 12/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=25992.07422]\n",
      "Epoch 13/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 275.81batch/s, loss=22559.95898]\n",
      "Epoch 13/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 113.55batch/s, loss=19299.80273]\n",
      "Epoch 14/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 164.36batch/s, loss=16314.09912]\n",
      "Epoch 14/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 248.86batch/s, loss=12326.10840]\n",
      "Epoch 15/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.52batch/s, loss=9756.23291]\n",
      "Epoch 15/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 389.30batch/s, loss=5984.74805]\n",
      "Epoch 16/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 201.01batch/s, loss=4440.03638]\n",
      "Epoch 16/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=1646.73828]\n",
      "Epoch 17/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 227.81batch/s, loss=1049.19873]\n",
      "Epoch 17/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 158.92batch/s, loss=898.73645]\n",
      "Epoch 18/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.38batch/s, loss=1256.83051]\n",
      "Epoch 18/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 470.95batch/s, loss=3329.67920]\n",
      "Epoch 19/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 219.87batch/s, loss=3569.87964]\n",
      "Epoch 19/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 356.78batch/s, loss=5001.40186]\n",
      "Epoch 20/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.55batch/s, loss=4509.16968]\n",
      "Epoch 20/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.67batch/s, loss=3950.46533]\n",
      "Epoch 21/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 252.27batch/s, loss=3190.48132]\n",
      "Epoch 21/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 428.95batch/s, loss=1788.32910]\n",
      "Epoch 22/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 210.40batch/s, loss=1310.76505]\n",
      "Epoch 22/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=470.85220]\n",
      "Epoch 23/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 211.84batch/s, loss=338.70238]\n",
      "Epoch 23/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 415.73batch/s, loss=301.40701]\n",
      "Epoch 24/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 241.45batch/s, loss=376.68719]\n",
      "Epoch 24/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=725.88873]\n",
      "Epoch 25/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 132.26batch/s, loss=793.86737]\n",
      "Epoch 25/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 890.70batch/s, loss=1158.98975]\n",
      "Epoch 26/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.21batch/s, loss=1118.85345]\n",
      "Epoch 26/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 398.70batch/s, loss=1288.02173]\n",
      "Epoch 27/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.76batch/s, loss=1169.37122]\n",
      "Epoch 27/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 367.28batch/s, loss=1099.61792]\n",
      "Epoch 28/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.05batch/s, loss=932.64969]\n",
      "Epoch 28/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 327.60batch/s, loss=721.03467]\n",
      "Epoch 29/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 247.09batch/s, loss=569.76175]\n",
      "Epoch 29/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 364.25batch/s, loss=353.56107]\n",
      "Epoch 30/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.83batch/s, loss=261.61854]\n",
      "Epoch 30/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 495.72batch/s, loss=162.90755]\n",
      "Epoch 31/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 242.82batch/s, loss=132.81526]\n",
      "Epoch 31/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 444.08batch/s, loss=184.66187]\n",
      "Epoch 32/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.36batch/s, loss=184.07420]\n",
      "Epoch 32/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=313.62054]\n",
      "Epoch 33/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.79batch/s, loss=299.37808]\n",
      "Epoch 33/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 307.97batch/s, loss=394.59421]\n",
      "Epoch 34/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.54batch/s, loss=347.74701]\n",
      "Epoch 34/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 270.43batch/s, loss=357.42462]\n",
      "Epoch 35/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.43batch/s, loss=292.00378]\n",
      "Epoch 35/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 188.00batch/s, loss=250.63567]\n",
      "Epoch 36/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 149.71batch/s, loss=194.70054]\n",
      "Epoch 36/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 297.24batch/s, loss=163.96059]\n",
      "Epoch 37/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 242.20batch/s, loss=129.94170]\n",
      "Epoch 37/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 342.42batch/s, loss=139.74739]\n",
      "Epoch 38/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 209.47batch/s, loss=120.41502]\n",
      "Epoch 38/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 287.38batch/s, loss=160.24982]\n",
      "Epoch 39/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.78batch/s, loss=144.21941]\n",
      "Epoch 39/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 445.02batch/s, loss=185.04976]\n",
      "Epoch 40/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.89batch/s, loss=163.65543]\n",
      "Epoch 40/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 390.13batch/s, loss=186.50861]\n",
      "Epoch 41/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.62batch/s, loss=159.37071]\n",
      "Epoch 41/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 471.43batch/s, loss=164.90703]\n",
      "Epoch 42/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 215.40batch/s, loss=136.72904]\n",
      "Epoch 42/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 518.97batch/s, loss=139.22247]\n",
      "Epoch 43/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.91batch/s, loss=115.70348]\n",
      "Epoch 43/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 360.77batch/s, loss=125.88869]\n",
      "Epoch 44/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 204.23batch/s, loss=107.65861]\n",
      "Epoch 44/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=128.15007]\n",
      "Epoch 45/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 123.80batch/s, loss=111.94110]\n",
      "Epoch 45/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 790.04batch/s, loss=136.18288]\n",
      "Epoch 46/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 249.28batch/s, loss=118.12986]\n",
      "Epoch 46/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 760.39batch/s, loss=138.65845]\n",
      "Epoch 47/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 236.87batch/s, loss=119.37943]\n",
      "Epoch 47/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 368.60batch/s, loss=133.97035]\n",
      "Epoch 48/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 232.73batch/s, loss=112.52544]\n",
      "Epoch 48/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 416.68batch/s, loss=126.07401]\n",
      "Epoch 49/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.69batch/s, loss=105.98539]\n",
      "Epoch 49/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 327.58batch/s, loss=122.04981]\n",
      "Epoch 50/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.35batch/s, loss=103.33242]\n",
      "Epoch 50/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 248.91batch/s, loss=123.00442]\n",
      "Epoch 51/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.09batch/s, loss=104.45967]\n",
      "Epoch 51/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 269.90batch/s, loss=125.82362]\n",
      "Epoch 52/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.30batch/s, loss=106.89040]\n",
      "Epoch 52/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 378.68batch/s, loss=126.95693]\n",
      "Epoch 53/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.38batch/s, loss=106.74595]\n",
      "Epoch 53/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 580.85batch/s, loss=125.52829]\n",
      "Epoch 54/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.83batch/s, loss=105.00913]\n",
      "Epoch 54/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 286.30batch/s, loss=123.09048]\n",
      "Epoch 55/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 259.66batch/s, loss=103.28710]\n",
      "Epoch 55/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 357.27batch/s, loss=122.00999]\n",
      "Epoch 56/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.44batch/s, loss=102.51217]\n",
      "Epoch 56/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 189.80batch/s, loss=122.02428]\n",
      "Epoch 57/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.35batch/s, loss=103.30008]\n",
      "Epoch 57/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=122.73702]\n",
      "Epoch 58/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.43batch/s, loss=103.35532]\n",
      "Epoch 58/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 247.23batch/s, loss=122.37257]\n",
      "Epoch 59/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 297.34batch/s, loss=103.46218]\n",
      "Epoch 59/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 126.69batch/s, loss=121.54488]\n",
      "Epoch 60/1000 - Training: 100%|██████████| 2/2 [00:00<?, ?batch/s, loss=102.22507]\n",
      "Epoch 60/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 65.11batch/s, loss=120.62486]\n",
      "Epoch 61/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 315.99batch/s, loss=101.89884]\n",
      "Epoch 61/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 112.58batch/s, loss=120.31835]\n",
      "Epoch 62/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.01batch/s, loss=101.48403]\n",
      "Epoch 62/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.49512]\n",
      "Epoch 63/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 125.31batch/s, loss=102.17634]\n",
      "Epoch 63/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 277.22batch/s, loss=120.72346]\n",
      "Epoch 64/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.80batch/s, loss=102.04848]\n",
      "Epoch 64/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 286.79batch/s, loss=120.71728]\n",
      "Epoch 65/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.85batch/s, loss=101.90163]\n",
      "Epoch 65/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.43batch/s, loss=120.55505]\n",
      "Epoch 66/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.97batch/s, loss=101.71830]\n",
      "Epoch 66/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 437.27batch/s, loss=120.66639]\n",
      "Epoch 67/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.51batch/s, loss=101.40205]\n",
      "Epoch 67/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 377.46batch/s, loss=120.83359]\n",
      "Epoch 68/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 151.32batch/s, loss=102.02598]\n",
      "Epoch 68/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=121.19621]\n",
      "Epoch 69/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.14batch/s, loss=102.08695]\n",
      "Epoch 69/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=121.24915]\n",
      "Epoch 70/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.64batch/s, loss=102.64350]\n",
      "Epoch 70/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 208.42batch/s, loss=121.30289]\n",
      "Epoch 71/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 157.61batch/s, loss=102.32803]\n",
      "Epoch 71/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 215.77batch/s, loss=120.98542]\n",
      "Epoch 72/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 237.16batch/s, loss=101.49943]\n",
      "Epoch 72/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 187.77batch/s, loss=120.87384]\n",
      "Epoch 73/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 219.25batch/s, loss=102.34827]\n",
      "Epoch 73/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 324.29batch/s, loss=121.00554]\n",
      "Epoch 74/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.16batch/s, loss=101.68069]\n",
      "Epoch 74/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 518.58batch/s, loss=120.95689]\n",
      "Epoch 75/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 208.77batch/s, loss=101.48504]\n",
      "Epoch 75/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 347.90batch/s, loss=120.81466]\n",
      "Epoch 76/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.58batch/s, loss=101.54965]\n",
      "Epoch 76/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.49batch/s, loss=120.65879]\n",
      "Epoch 77/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.64batch/s, loss=101.41344]\n",
      "Epoch 77/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 635.89batch/s, loss=120.62614]\n",
      "Epoch 78/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.47batch/s, loss=101.43427]\n",
      "Epoch 78/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 262.34batch/s, loss=120.66736]\n",
      "Epoch 79/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.38batch/s, loss=102.34231]\n",
      "Epoch 79/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.72310]\n",
      "Epoch 80/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.26batch/s, loss=101.66699]\n",
      "Epoch 80/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.69704]\n",
      "Epoch 81/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.59batch/s, loss=102.12133]\n",
      "Epoch 81/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 515.71batch/s, loss=120.66572]\n",
      "Epoch 82/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.14batch/s, loss=101.71069]\n",
      "Epoch 82/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.67926]\n",
      "Epoch 83/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 201.29batch/s, loss=101.53419]\n",
      "Epoch 83/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.53434]\n",
      "Epoch 84/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 145.83batch/s, loss=101.51656]\n",
      "Epoch 84/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 494.55batch/s, loss=120.59077]\n",
      "Epoch 85/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 135.69batch/s, loss=101.75351]\n",
      "Epoch 85/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.04batch/s, loss=120.72916]\n",
      "Epoch 86/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.85batch/s, loss=101.81451]\n",
      "Epoch 86/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 533.42batch/s, loss=120.83097]\n",
      "Epoch 87/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 151.56batch/s, loss=101.48087]\n",
      "Epoch 87/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.81934]\n",
      "Epoch 88/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 145.45batch/s, loss=101.93320]\n",
      "Epoch 88/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 307.84batch/s, loss=120.63895]\n",
      "Epoch 89/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.97batch/s, loss=101.43468]\n",
      "Epoch 89/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 343.96batch/s, loss=120.67166]\n",
      "Epoch 90/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 234.65batch/s, loss=101.98524]\n",
      "Epoch 90/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.73088]\n",
      "Epoch 91/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.92batch/s, loss=102.08904]\n",
      "Epoch 91/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 765.10batch/s, loss=120.86705]\n",
      "Epoch 92/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 150.03batch/s, loss=101.73956]\n",
      "Epoch 92/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 521.10batch/s, loss=120.87571]\n",
      "Epoch 93/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.81batch/s, loss=101.47112]\n",
      "Epoch 93/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.67batch/s, loss=120.79025]\n",
      "Epoch 94/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.79batch/s, loss=101.57885]\n",
      "Epoch 94/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 500.63batch/s, loss=120.61666]\n",
      "Epoch 95/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.38batch/s, loss=102.24364]\n",
      "Epoch 95/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.54batch/s, loss=120.73847]\n",
      "Epoch 96/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.23batch/s, loss=101.96334]\n",
      "Epoch 96/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 667.46batch/s, loss=120.67661]\n",
      "Epoch 97/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 265.96batch/s, loss=101.75533]\n",
      "Epoch 97/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 438.55batch/s, loss=120.46018]\n",
      "Epoch 98/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 223.57batch/s, loss=101.89172]\n",
      "Epoch 98/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 389.41batch/s, loss=120.47482]\n",
      "Epoch 99/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 307.22batch/s, loss=101.41124]\n",
      "Epoch 99/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 118.64batch/s, loss=120.44929]\n",
      "Epoch 100/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 130.31batch/s, loss=101.78127]\n",
      "Epoch 100/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 198.95batch/s, loss=120.50080]\n",
      "Epoch 101/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.67batch/s, loss=101.40115]\n",
      "Epoch 101/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.56245]\n",
      "Epoch 102/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 114.78batch/s, loss=101.67280]\n",
      "Epoch 102/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 638.01batch/s, loss=120.59201]\n",
      "Epoch 103/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.67batch/s, loss=101.85692]\n",
      "Epoch 103/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 995.33batch/s, loss=120.42528]\n",
      "Epoch 104/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.06batch/s, loss=101.65723]\n",
      "Epoch 104/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 521.03batch/s, loss=120.51199]\n",
      "Epoch 105/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 140.50batch/s, loss=101.52196]\n",
      "Epoch 105/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 536.42batch/s, loss=120.64356]\n",
      "Epoch 106/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.08batch/s, loss=101.94354]\n",
      "Epoch 106/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 480.17batch/s, loss=120.75993]\n",
      "Epoch 107/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.18batch/s, loss=101.41576]\n",
      "Epoch 107/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.78002]\n",
      "Epoch 108/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 110.29batch/s, loss=101.84636]\n",
      "Epoch 108/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 765.52batch/s, loss=120.83472]\n",
      "Epoch 109/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.61batch/s, loss=101.54412]\n",
      "Epoch 109/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 327.53batch/s, loss=120.65346]\n",
      "Epoch 110/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 237.39batch/s, loss=101.20703]\n",
      "Epoch 110/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 746.98batch/s, loss=120.72065]\n",
      "Epoch 111/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 196.11batch/s, loss=102.05531]\n",
      "Epoch 111/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 403.03batch/s, loss=120.42094]\n",
      "Epoch 112/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 231.97batch/s, loss=101.74840]\n",
      "Epoch 112/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 280.95batch/s, loss=120.48031]\n",
      "Epoch 113/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.40batch/s, loss=102.53030]\n",
      "Epoch 113/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 591.66batch/s, loss=120.37876]\n",
      "Epoch 114/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 205.99batch/s, loss=101.91907]\n",
      "Epoch 114/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 697.42batch/s, loss=120.48347]\n",
      "Epoch 115/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.28batch/s, loss=101.47734]\n",
      "Epoch 115/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 358.21batch/s, loss=120.49003]\n",
      "Epoch 116/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 162.47batch/s, loss=102.26367]\n",
      "Epoch 116/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 317.68batch/s, loss=120.80717]\n",
      "Epoch 117/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.36batch/s, loss=101.39415]\n",
      "Epoch 117/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 192.21batch/s, loss=120.83216]\n",
      "Epoch 118/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.46batch/s, loss=101.41625]\n",
      "Epoch 118/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 162.15batch/s, loss=120.90739]\n",
      "Epoch 119/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 157.75batch/s, loss=101.51363]\n",
      "Epoch 119/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.80862]\n",
      "Epoch 120/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 122.44batch/s, loss=101.02024]\n",
      "Epoch 120/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 753.56batch/s, loss=120.69434]\n",
      "Epoch 121/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.99batch/s, loss=101.44270]\n",
      "Epoch 121/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.61345]\n",
      "Epoch 122/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 142.07batch/s, loss=101.65585]\n",
      "Epoch 122/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 291.07batch/s, loss=120.65870]\n",
      "Epoch 123/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.28batch/s, loss=101.55048]\n",
      "Epoch 123/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.71494]\n",
      "Epoch 124/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 117.33batch/s, loss=101.51015]\n",
      "Epoch 124/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 306.24batch/s, loss=120.66566]\n",
      "Epoch 125/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.77batch/s, loss=101.84495]\n",
      "Epoch 125/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 784.86batch/s, loss=120.75199]\n",
      "Epoch 126/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 200.60batch/s, loss=101.98911]\n",
      "Epoch 126/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.78150]\n",
      "Epoch 127/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 130.43batch/s, loss=101.63501]\n",
      "Epoch 127/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.49588]\n",
      "Epoch 128/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 125.02batch/s, loss=101.10158]\n",
      "Epoch 128/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 513.88batch/s, loss=120.43687]\n",
      "Epoch 129/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.75batch/s, loss=101.32178]\n",
      "Epoch 129/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 380.95batch/s, loss=120.47588]\n",
      "Epoch 130/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.50batch/s, loss=102.37505]\n",
      "Epoch 130/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 324.61batch/s, loss=120.82381]\n",
      "Epoch 131/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.72batch/s, loss=101.50051]\n",
      "Epoch 131/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 307.93batch/s, loss=120.85062]\n",
      "Epoch 132/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 135.27batch/s, loss=101.32473]\n",
      "Epoch 132/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 467.33batch/s, loss=120.71783]\n",
      "Epoch 133/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 284.18batch/s, loss=101.87976]\n",
      "Epoch 133/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 339.15batch/s, loss=120.52892]\n",
      "Epoch 134/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 206.18batch/s, loss=101.64890]\n",
      "Epoch 134/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 459.55batch/s, loss=120.43721]\n",
      "Epoch 135/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.82batch/s, loss=101.64898]\n",
      "Epoch 135/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.92batch/s, loss=120.45270]\n",
      "Epoch 136/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 248.37batch/s, loss=102.32924]\n",
      "Epoch 136/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 449.79batch/s, loss=120.56211]\n",
      "Epoch 137/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.60batch/s, loss=101.60386]\n",
      "Epoch 137/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.81batch/s, loss=120.55037]\n",
      "Epoch 138/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.02batch/s, loss=101.55244]\n",
      "Epoch 138/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 450.71batch/s, loss=120.41751]\n",
      "Epoch 139/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.05batch/s, loss=101.93239]\n",
      "Epoch 139/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 429.79batch/s, loss=120.55144]\n",
      "Epoch 140/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.82batch/s, loss=101.62795]\n",
      "Epoch 140/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 219.33batch/s, loss=120.55611]\n",
      "Epoch 141/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 213.23batch/s, loss=101.20248]\n",
      "Epoch 141/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 389.30batch/s, loss=120.69758]\n",
      "Epoch 142/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 255.07batch/s, loss=102.15385]\n",
      "Epoch 142/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 148.26batch/s, loss=120.95159]\n",
      "Epoch 143/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.70batch/s, loss=101.55157]\n",
      "Epoch 143/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 139.62batch/s, loss=120.79572]\n",
      "Epoch 144/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 142.80batch/s, loss=102.28402]\n",
      "Epoch 144/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.25batch/s, loss=120.60526]\n",
      "Epoch 145/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 212.82batch/s, loss=101.64545]\n",
      "Epoch 145/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 287.81batch/s, loss=120.57332]\n",
      "Epoch 146/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.68batch/s, loss=101.36245]\n",
      "Epoch 146/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 490.91batch/s, loss=120.53666]\n",
      "Epoch 147/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.62batch/s, loss=101.98196]\n",
      "Epoch 147/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 313.38batch/s, loss=120.37193]\n",
      "Epoch 148/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.79batch/s, loss=101.29906]\n",
      "Epoch 148/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 3134.76batch/s, loss=120.50173]\n",
      "Epoch 149/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.51batch/s, loss=101.24163]\n",
      "Epoch 149/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 409.92batch/s, loss=120.50127]\n",
      "Epoch 150/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.42batch/s, loss=101.46203]\n",
      "Epoch 150/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.54641]\n",
      "Epoch 151/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 114.01batch/s, loss=101.45571]\n",
      "Epoch 151/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 338.20batch/s, loss=120.76694]\n",
      "Epoch 152/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.41batch/s, loss=101.13391]\n",
      "Epoch 152/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 356.02batch/s, loss=120.81017]\n",
      "Epoch 153/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 207.32batch/s, loss=101.54150]\n",
      "Epoch 153/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 188.09batch/s, loss=120.85067]\n",
      "Epoch 154/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.52batch/s, loss=101.73308]\n",
      "Epoch 154/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.85210]\n",
      "Epoch 155/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 217.20batch/s, loss=101.40094]\n",
      "Epoch 155/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 464.54batch/s, loss=120.60100]\n",
      "Epoch 156/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.48batch/s, loss=101.86390]\n",
      "Epoch 156/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 812.85batch/s, loss=120.51765]\n",
      "Epoch 157/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 207.68batch/s, loss=101.35603]\n",
      "Epoch 157/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.47583]\n",
      "Epoch 158/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 126.85batch/s, loss=101.83226]\n",
      "Epoch 158/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 328.73batch/s, loss=120.33368]\n",
      "Epoch 159/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.41batch/s, loss=101.71148]\n",
      "Epoch 159/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 299.66batch/s, loss=120.25063]\n",
      "Epoch 160/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.98batch/s, loss=101.71785]\n",
      "Epoch 160/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 412.91batch/s, loss=120.43798]\n",
      "Epoch 161/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 210.00batch/s, loss=101.66095]\n",
      "Epoch 161/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 869.83batch/s, loss=120.50946]\n",
      "Epoch 162/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.55batch/s, loss=101.41439]\n",
      "Epoch 162/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 285.42batch/s, loss=120.55090]\n",
      "Epoch 163/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 200.96batch/s, loss=101.35410]\n",
      "Epoch 163/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.64302]\n",
      "Epoch 164/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.19batch/s, loss=101.72885]\n",
      "Epoch 164/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.83344]\n",
      "Epoch 165/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 213.36batch/s, loss=101.26114]\n",
      "Epoch 165/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 369.05batch/s, loss=120.77431]\n",
      "Epoch 166/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 161.05batch/s, loss=101.79125]\n",
      "Epoch 166/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 382.87batch/s, loss=120.74976]\n",
      "Epoch 167/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.05batch/s, loss=101.32992]\n",
      "Epoch 167/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 412.83batch/s, loss=120.54518]\n",
      "Epoch 168/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 231.90batch/s, loss=102.14990]\n",
      "Epoch 168/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 136.83batch/s, loss=120.64255]\n",
      "Epoch 169/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.93batch/s, loss=101.86269]\n",
      "Epoch 169/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.88batch/s, loss=120.40105]\n",
      "Epoch 170/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.51batch/s, loss=102.40891]\n",
      "Epoch 170/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 337.19batch/s, loss=120.52989]\n",
      "Epoch 171/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 210.71batch/s, loss=101.41483]\n",
      "Epoch 171/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 423.20batch/s, loss=120.43874]\n",
      "Epoch 172/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.92batch/s, loss=101.40744]\n",
      "Epoch 172/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 225.96batch/s, loss=120.54079]\n",
      "Epoch 173/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 212.76batch/s, loss=101.86782]\n",
      "Epoch 173/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 416.18batch/s, loss=120.61820]\n",
      "Epoch 174/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 219.24batch/s, loss=102.06474]\n",
      "Epoch 174/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 388.15batch/s, loss=120.60913]\n",
      "Epoch 175/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.96batch/s, loss=101.16235]\n",
      "Epoch 175/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 259.08batch/s, loss=120.55137]\n",
      "Epoch 176/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.50batch/s, loss=101.22169]\n",
      "Epoch 176/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.38655]\n",
      "Epoch 177/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 118.61batch/s, loss=101.64856]\n",
      "Epoch 177/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 536.36batch/s, loss=120.37384]\n",
      "Epoch 178/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.25batch/s, loss=101.62475]\n",
      "Epoch 178/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 374.39batch/s, loss=120.57053]\n",
      "Epoch 179/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.88batch/s, loss=101.58849]\n",
      "Epoch 179/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.52061]\n",
      "Epoch 180/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 141.43batch/s, loss=101.36921]\n",
      "Epoch 180/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 319.13batch/s, loss=120.41829]\n",
      "Epoch 181/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.26batch/s, loss=101.06296]\n",
      "Epoch 181/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.40447]\n",
      "Epoch 182/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.06batch/s, loss=101.50009]\n",
      "Epoch 182/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 567.18batch/s, loss=120.57870]\n",
      "Epoch 183/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.75batch/s, loss=101.09988]\n",
      "Epoch 183/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 406.39batch/s, loss=120.56088]\n",
      "Epoch 184/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.34batch/s, loss=101.75730]\n",
      "Epoch 184/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.64536]\n",
      "Epoch 185/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 141.72batch/s, loss=101.56782]\n",
      "Epoch 185/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.55685]\n",
      "Epoch 186/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 123.42batch/s, loss=101.63630]\n",
      "Epoch 186/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 429.79batch/s, loss=120.56116]\n",
      "Epoch 187/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.65batch/s, loss=101.57228]\n",
      "Epoch 187/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.56615]\n",
      "Epoch 188/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 97.72batch/s, loss=101.49763]\n",
      "Epoch 188/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1159.29batch/s, loss=120.56422]\n",
      "Epoch 189/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 132.84batch/s, loss=101.84029]\n",
      "Epoch 189/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.53860]\n",
      "Epoch 190/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 117.51batch/s, loss=100.93467]\n",
      "Epoch 190/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 134.45batch/s, loss=120.37609]\n",
      "Epoch 191/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 309.57batch/s, loss=101.10624]\n",
      "Epoch 191/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 119.15batch/s, loss=120.27320]\n",
      "Epoch 192/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 393.09batch/s, loss=101.53025]\n",
      "Epoch 192/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 87.82batch/s, loss=120.32067]\n",
      "Epoch 193/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.08batch/s, loss=101.65139]\n",
      "Epoch 193/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 536.97batch/s, loss=120.49036]\n",
      "Epoch 194/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 250.67batch/s, loss=101.26001]\n",
      "Epoch 194/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 146.65batch/s, loss=120.56354]\n",
      "Epoch 195/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.91batch/s, loss=101.85715]\n",
      "Epoch 195/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 493.04batch/s, loss=120.60085]\n",
      "Epoch 196/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 145.03batch/s, loss=101.98415]\n",
      "Epoch 196/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.63606]\n",
      "Epoch 197/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 157.78batch/s, loss=101.97150]\n",
      "Epoch 197/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.67batch/s, loss=120.54780]\n",
      "Epoch 198/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.63batch/s, loss=101.92489]\n",
      "Epoch 198/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 314.89batch/s, loss=120.43981]\n",
      "Epoch 199/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.51batch/s, loss=101.58150]\n",
      "Epoch 199/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 200.37batch/s, loss=120.10581]\n",
      "Epoch 200/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 113.24batch/s, loss=101.21547]\n",
      "Epoch 200/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 173.61batch/s, loss=120.10219]\n",
      "Epoch 201/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.71batch/s, loss=101.88681]\n",
      "Epoch 201/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 247.83batch/s, loss=120.12267]\n",
      "Epoch 202/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.54batch/s, loss=101.38970]\n",
      "Epoch 202/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 311.82batch/s, loss=120.24799]\n",
      "Epoch 203/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.60batch/s, loss=101.77587]\n",
      "Epoch 203/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 273.12batch/s, loss=120.46368]\n",
      "Epoch 204/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.63batch/s, loss=101.45248]\n",
      "Epoch 204/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 481.44batch/s, loss=120.53717]\n",
      "Epoch 205/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 210.56batch/s, loss=101.34308]\n",
      "Epoch 205/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.52799]\n",
      "Epoch 206/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.68batch/s, loss=101.54509]\n",
      "Epoch 206/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 450.56batch/s, loss=120.46296]\n",
      "Epoch 207/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.09batch/s, loss=101.15392]\n",
      "Epoch 207/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.13batch/s, loss=120.59373]\n",
      "Epoch 208/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 125.46batch/s, loss=101.56364]\n",
      "Epoch 208/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 505.58batch/s, loss=120.79426]\n",
      "Epoch 209/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.11batch/s, loss=101.90621]\n",
      "Epoch 209/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.56944]\n",
      "Epoch 210/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.15batch/s, loss=101.36576]\n",
      "Epoch 210/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 453.29batch/s, loss=120.60246]\n",
      "Epoch 211/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 222.33batch/s, loss=101.44847]\n",
      "Epoch 211/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 466.09batch/s, loss=120.56036]\n",
      "Epoch 212/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.18batch/s, loss=101.09460]\n",
      "Epoch 212/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 465.05batch/s, loss=120.37638]\n",
      "Epoch 213/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.48batch/s, loss=101.44902]\n",
      "Epoch 213/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 387.97batch/s, loss=120.48045]\n",
      "Epoch 214/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.16batch/s, loss=101.88826]\n",
      "Epoch 214/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 456.00batch/s, loss=120.65055]\n",
      "Epoch 215/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.52batch/s, loss=101.64968]\n",
      "Epoch 215/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.36110]\n",
      "Epoch 216/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 247.09batch/s, loss=101.66562]\n",
      "Epoch 216/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 419.35batch/s, loss=120.44518]\n",
      "Epoch 217/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.37batch/s, loss=101.72584]\n",
      "Epoch 217/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 584.57batch/s, loss=120.47928]\n",
      "Epoch 218/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.27batch/s, loss=102.06532]\n",
      "Epoch 218/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.44batch/s, loss=120.39201]\n",
      "Epoch 219/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.30batch/s, loss=101.60234]\n",
      "Epoch 219/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 222.84batch/s, loss=120.36378]\n",
      "Epoch 220/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.50batch/s, loss=101.34313]\n",
      "Epoch 220/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 996.27batch/s, loss=120.15195]\n",
      "Epoch 221/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.11batch/s, loss=101.40541]\n",
      "Epoch 221/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.98batch/s, loss=120.31624]\n",
      "Epoch 222/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.36batch/s, loss=101.38358]\n",
      "Epoch 222/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.33598]\n",
      "Epoch 223/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.04batch/s, loss=101.45958]\n",
      "Epoch 223/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 282.18batch/s, loss=120.55894]\n",
      "Epoch 224/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 146.36batch/s, loss=100.51918]\n",
      "Epoch 224/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 467.85batch/s, loss=120.45570]\n",
      "Epoch 225/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.98batch/s, loss=101.74597]\n",
      "Epoch 225/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 500.10batch/s, loss=120.60950]\n",
      "Epoch 226/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.13batch/s, loss=101.49342]\n",
      "Epoch 226/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 301.44batch/s, loss=120.55976]\n",
      "Epoch 227/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.85batch/s, loss=101.45985]\n",
      "Epoch 227/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 442.02batch/s, loss=120.45502]\n",
      "Epoch 228/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.53batch/s, loss=101.67555]\n",
      "Epoch 228/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 510.07batch/s, loss=120.44187]\n",
      "Epoch 229/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.00batch/s, loss=101.75809]\n",
      "Epoch 229/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.00batch/s, loss=120.09419]\n",
      "Epoch 230/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.89batch/s, loss=101.52515]\n",
      "Epoch 230/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 607.87batch/s, loss=119.94279]\n",
      "Epoch 231/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 375.14batch/s, loss=101.18996]\n",
      "Epoch 231/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 314.63batch/s, loss=119.89921]\n",
      "Epoch 232/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.72batch/s, loss=101.56669]\n",
      "Epoch 232/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 786.04batch/s, loss=120.22739]\n",
      "Epoch 233/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 100.32batch/s, loss=101.76911]\n",
      "Epoch 233/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 207.18batch/s, loss=120.51191]\n",
      "Epoch 234/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.71batch/s, loss=101.54780]\n",
      "Epoch 234/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 259.90batch/s, loss=120.74445]\n",
      "Epoch 235/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.53batch/s, loss=101.58176]\n",
      "Epoch 235/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.25batch/s, loss=120.75910]\n",
      "Epoch 236/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.49batch/s, loss=102.19458]\n",
      "Epoch 236/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 257.40batch/s, loss=120.73059]\n",
      "Epoch 237/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.40batch/s, loss=101.53181]\n",
      "Epoch 237/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 805.98batch/s, loss=120.29433]\n",
      "Epoch 238/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.17batch/s, loss=101.62607]\n",
      "Epoch 238/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 255.77batch/s, loss=120.21562]\n",
      "Epoch 239/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.75batch/s, loss=101.61384]\n",
      "Epoch 239/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 283.46batch/s, loss=120.12034]\n",
      "Epoch 240/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.03batch/s, loss=101.07164]\n",
      "Epoch 240/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 462.69batch/s, loss=120.15636]\n",
      "Epoch 241/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 207.68batch/s, loss=101.40852]\n",
      "Epoch 241/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 435.95batch/s, loss=120.39500]\n",
      "Epoch 242/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.01batch/s, loss=101.76692]\n",
      "Epoch 242/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 236.38batch/s, loss=120.41613]\n",
      "Epoch 243/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 129.35batch/s, loss=101.57092]\n",
      "Epoch 243/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 314.51batch/s, loss=120.29501]\n",
      "Epoch 244/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.88batch/s, loss=101.51952]\n",
      "Epoch 244/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 285.58batch/s, loss=120.21953]\n",
      "Epoch 245/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 218.48batch/s, loss=101.07072]\n",
      "Epoch 245/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 386.46batch/s, loss=120.15213]\n",
      "Epoch 246/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.22batch/s, loss=101.78753]\n",
      "Epoch 246/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 958.92batch/s, loss=120.35714]\n",
      "Epoch 247/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.48batch/s, loss=101.34250]\n",
      "Epoch 247/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.21batch/s, loss=120.58284]\n",
      "Epoch 248/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 143.56batch/s, loss=101.68951]\n",
      "Epoch 248/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 177.26batch/s, loss=120.73524]\n",
      "Epoch 249/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 130.70batch/s, loss=101.82335]\n",
      "Epoch 249/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 640.25batch/s, loss=120.61130]\n",
      "Epoch 250/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 237.38batch/s, loss=101.69889]\n",
      "Epoch 250/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.25batch/s, loss=120.50484]\n",
      "Epoch 251/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 200.44batch/s, loss=101.08080]\n",
      "Epoch 251/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.25140]\n",
      "Epoch 252/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.54batch/s, loss=101.42896]\n",
      "Epoch 252/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.70batch/s, loss=120.25780]\n",
      "Epoch 253/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.96batch/s, loss=101.71867]\n",
      "Epoch 253/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 295.62batch/s, loss=120.27288]\n",
      "Epoch 254/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.61batch/s, loss=101.83543]\n",
      "Epoch 254/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 297.07batch/s, loss=120.49151]\n",
      "Epoch 255/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.34batch/s, loss=101.56879]\n",
      "Epoch 255/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 354.85batch/s, loss=120.38287]\n",
      "Epoch 256/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.14batch/s, loss=101.60989]\n",
      "Epoch 256/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.37720]\n",
      "Epoch 257/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 201.11batch/s, loss=101.08400]\n",
      "Epoch 257/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 756.28batch/s, loss=120.10700]\n",
      "Epoch 258/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 138.97batch/s, loss=101.62119]\n",
      "Epoch 258/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 218.42batch/s, loss=120.15745]\n",
      "Epoch 259/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.80batch/s, loss=100.86255]\n",
      "Epoch 259/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.27batch/s, loss=120.15661]\n",
      "Epoch 260/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 164.13batch/s, loss=101.09557]\n",
      "Epoch 260/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.11942]\n",
      "Epoch 261/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 208.02batch/s, loss=101.73004]\n",
      "Epoch 261/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 190.36batch/s, loss=120.03239]\n",
      "Epoch 262/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 96.81batch/s, loss=101.73120]\n",
      "Epoch 262/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 159.72batch/s, loss=120.32124]\n",
      "Epoch 263/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.39batch/s, loss=100.96128]\n",
      "Epoch 263/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 288.49batch/s, loss=120.39951]\n",
      "Epoch 264/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.72batch/s, loss=101.36063]\n",
      "Epoch 264/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 459.75batch/s, loss=120.53999]\n",
      "Epoch 265/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.49batch/s, loss=101.57717]\n",
      "Epoch 265/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.92batch/s, loss=120.45424]\n",
      "Epoch 266/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 219.93batch/s, loss=100.68098]\n",
      "Epoch 266/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 722.04batch/s, loss=120.46804]\n",
      "Epoch 267/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.82batch/s, loss=101.58664]\n",
      "Epoch 267/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 486.52batch/s, loss=120.53225]\n",
      "Epoch 268/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 146.88batch/s, loss=101.83692]\n",
      "Epoch 268/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 376.41batch/s, loss=120.37954]\n",
      "Epoch 269/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.12batch/s, loss=101.27101]\n",
      "Epoch 269/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 241.57batch/s, loss=120.36565]\n",
      "Epoch 270/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 239.95batch/s, loss=102.06362]\n",
      "Epoch 270/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 115.11batch/s, loss=120.47816]\n",
      "Epoch 271/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 224.23batch/s, loss=101.72175]\n",
      "Epoch 271/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 437.36batch/s, loss=120.25172]\n",
      "Epoch 272/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 284.64batch/s, loss=101.54916]\n",
      "Epoch 272/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 346.78batch/s, loss=120.14187]\n",
      "Epoch 273/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 311.76batch/s, loss=101.53933]\n",
      "Epoch 273/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.90batch/s, loss=120.03461]\n",
      "Epoch 274/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 264.85batch/s, loss=101.37267]\n",
      "Epoch 274/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 166.66batch/s, loss=119.86610]\n",
      "Epoch 275/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 205.50batch/s, loss=100.86702]\n",
      "Epoch 275/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 406.98batch/s, loss=119.90176]\n",
      "Epoch 276/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.30batch/s, loss=101.03127]\n",
      "Epoch 276/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 196.12batch/s, loss=119.91782]\n",
      "Epoch 277/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.45batch/s, loss=101.96220]\n",
      "Epoch 277/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 306.96batch/s, loss=120.21817]\n",
      "Epoch 278/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.63batch/s, loss=101.43416]\n",
      "Epoch 278/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 248.17batch/s, loss=120.71834]\n",
      "Epoch 279/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.67batch/s, loss=101.04260]\n",
      "Epoch 279/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 165.33batch/s, loss=120.65665]\n",
      "Epoch 280/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 254.45batch/s, loss=101.03604]\n",
      "Epoch 280/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 222.19batch/s, loss=120.52474]\n",
      "Epoch 281/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.16batch/s, loss=101.38036]\n",
      "Epoch 281/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 420.27batch/s, loss=120.21946]\n",
      "Epoch 282/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.43batch/s, loss=101.23938]\n",
      "Epoch 282/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.61batch/s, loss=120.30893]\n",
      "Epoch 283/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.07batch/s, loss=100.95978]\n",
      "Epoch 283/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 477.77batch/s, loss=120.43554]\n",
      "Epoch 284/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.69batch/s, loss=101.62057]\n",
      "Epoch 284/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.59985]\n",
      "Epoch 285/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.95batch/s, loss=101.16980]\n",
      "Epoch 285/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 315.24batch/s, loss=120.19715]\n",
      "Epoch 286/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 201.78batch/s, loss=101.03358]\n",
      "Epoch 286/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 275.96batch/s, loss=120.13281]\n",
      "Epoch 287/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 275.08batch/s, loss=101.31784]\n",
      "Epoch 287/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 441.23batch/s, loss=120.10442]\n",
      "Epoch 288/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.28batch/s, loss=101.26249]\n",
      "Epoch 288/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 380.40batch/s, loss=119.95049]\n",
      "Epoch 289/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 316.63batch/s, loss=101.62420]\n",
      "Epoch 289/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 663.66batch/s, loss=120.01574]\n",
      "Epoch 290/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.94batch/s, loss=101.08562]\n",
      "Epoch 290/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 639.86batch/s, loss=120.09404]\n",
      "Epoch 291/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 106.28batch/s, loss=101.46154]\n",
      "Epoch 291/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 421.50batch/s, loss=120.14693]\n",
      "Epoch 292/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.42batch/s, loss=101.23196]\n",
      "Epoch 292/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 235.62batch/s, loss=120.02487]\n",
      "Epoch 293/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.16batch/s, loss=101.49758]\n",
      "Epoch 293/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 262.06batch/s, loss=120.13960]\n",
      "Epoch 294/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.52batch/s, loss=101.83210]\n",
      "Epoch 294/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 325.97batch/s, loss=120.65194]\n",
      "Epoch 295/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.33batch/s, loss=101.95784]\n",
      "Epoch 295/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 397.56batch/s, loss=120.79066]\n",
      "Epoch 296/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 150.71batch/s, loss=101.56123]\n",
      "Epoch 296/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1190.21batch/s, loss=120.57978]\n",
      "Epoch 297/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.71batch/s, loss=101.86532]\n",
      "Epoch 297/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=119.93585]\n",
      "Epoch 298/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.26batch/s, loss=101.31174]\n",
      "Epoch 298/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 462.64batch/s, loss=119.82204]\n",
      "Epoch 299/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 262.01batch/s, loss=101.79159]\n",
      "Epoch 299/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 386.07batch/s, loss=119.91255]\n",
      "Epoch 300/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 264.45batch/s, loss=101.39001]\n",
      "Epoch 300/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 583.11batch/s, loss=119.94687]\n",
      "Epoch 301/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.34batch/s, loss=101.99533]\n",
      "Epoch 301/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 293.29batch/s, loss=120.04212]\n",
      "Epoch 302/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 301.61batch/s, loss=101.24612]\n",
      "Epoch 302/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.08batch/s, loss=120.10214]\n",
      "Epoch 303/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 319.69batch/s, loss=101.67366]\n",
      "Epoch 303/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.67batch/s, loss=120.19956]\n",
      "Epoch 304/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.83batch/s, loss=100.85520]\n",
      "Epoch 304/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 193.78batch/s, loss=119.92509]\n",
      "Epoch 305/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.62batch/s, loss=101.60355]\n",
      "Epoch 305/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 244.14batch/s, loss=119.96841]\n",
      "Epoch 306/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 161.33batch/s, loss=101.35865]\n",
      "Epoch 306/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.04559]\n",
      "Epoch 307/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 131.74batch/s, loss=101.07834]\n",
      "Epoch 307/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 400.56batch/s, loss=119.97277]\n",
      "Epoch 308/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.18batch/s, loss=101.24041]\n",
      "Epoch 308/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.14999]\n",
      "Epoch 309/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.03batch/s, loss=101.67176]\n",
      "Epoch 309/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 638.50batch/s, loss=120.60414]\n",
      "Epoch 310/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 144.68batch/s, loss=101.21206]\n",
      "Epoch 310/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 219.95batch/s, loss=120.56835]\n",
      "Epoch 311/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 149.63batch/s, loss=101.27322]\n",
      "Epoch 311/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 288.80batch/s, loss=120.12522]\n",
      "Epoch 312/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 209.81batch/s, loss=101.66840]\n",
      "Epoch 312/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 294.40batch/s, loss=120.18932]\n",
      "Epoch 313/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.41batch/s, loss=101.04231]\n",
      "Epoch 313/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 308.16batch/s, loss=119.87466]\n",
      "Epoch 314/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.31batch/s, loss=101.34748]\n",
      "Epoch 314/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 467.44batch/s, loss=119.56156]\n",
      "Epoch 315/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 395.54batch/s, loss=101.17944]\n",
      "Epoch 315/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 275.23batch/s, loss=119.67525]\n",
      "Epoch 316/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 261.67batch/s, loss=101.13995]\n",
      "Epoch 316/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 190.70batch/s, loss=119.84460]\n",
      "Epoch 317/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.00batch/s, loss=101.66547]\n",
      "Epoch 317/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 380.71batch/s, loss=120.25265]\n",
      "Epoch 318/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.91batch/s, loss=100.49409]\n",
      "Epoch 318/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 208.65batch/s, loss=120.15553]\n",
      "Epoch 319/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.26batch/s, loss=100.75694]\n",
      "Epoch 319/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 399.80batch/s, loss=120.02229]\n",
      "Epoch 320/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.66batch/s, loss=101.34963]\n",
      "Epoch 320/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 656.69batch/s, loss=119.90741]\n",
      "Epoch 321/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 162.12batch/s, loss=101.34769]\n",
      "Epoch 321/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 3024.01batch/s, loss=119.90312]\n",
      "Epoch 322/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.83batch/s, loss=100.93897]\n",
      "Epoch 322/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 164.26batch/s, loss=120.14800]\n",
      "Epoch 323/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.14batch/s, loss=100.89727]\n",
      "Epoch 323/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 347.87batch/s, loss=120.24023]\n",
      "Epoch 324/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 230.62batch/s, loss=100.89896]\n",
      "Epoch 324/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 227.22batch/s, loss=120.25445]\n",
      "Epoch 325/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.14batch/s, loss=100.89557]\n",
      "Epoch 325/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 240.36batch/s, loss=119.79497]\n",
      "Epoch 326/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.28batch/s, loss=100.48033]\n",
      "Epoch 326/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 350.55batch/s, loss=119.65273]\n",
      "Epoch 327/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.76batch/s, loss=101.76908]\n",
      "Epoch 327/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 430.58batch/s, loss=119.77990]\n",
      "Epoch 328/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.86batch/s, loss=101.51545]\n",
      "Epoch 328/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 362.39batch/s, loss=120.08805]\n",
      "Epoch 329/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.97batch/s, loss=100.58858]\n",
      "Epoch 329/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 373.66batch/s, loss=120.00167]\n",
      "Epoch 330/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 281.98batch/s, loss=100.83725]\n",
      "Epoch 330/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.02batch/s, loss=119.92836]\n",
      "Epoch 331/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.07batch/s, loss=101.01269]\n",
      "Epoch 331/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 357.36batch/s, loss=119.83187]\n",
      "Epoch 332/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.21batch/s, loss=101.25716]\n",
      "Epoch 332/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 297.81batch/s, loss=120.00682]\n",
      "Epoch 333/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.19batch/s, loss=100.93792]\n",
      "Epoch 333/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 353.56batch/s, loss=120.01548]\n",
      "Epoch 334/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.51batch/s, loss=100.91302]\n",
      "Epoch 334/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 312.63batch/s, loss=119.95645]\n",
      "Epoch 335/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.04batch/s, loss=101.21675]\n",
      "Epoch 335/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.22batch/s, loss=120.05148]\n",
      "Epoch 336/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 150.02batch/s, loss=100.29975]\n",
      "Epoch 336/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=120.02297]\n",
      "Epoch 337/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 200.67batch/s, loss=100.68882]\n",
      "Epoch 337/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.57batch/s, loss=119.88177]\n",
      "Epoch 338/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.68batch/s, loss=101.29002]\n",
      "Epoch 338/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 477.44batch/s, loss=119.96156]\n",
      "Epoch 339/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.42batch/s, loss=100.62695]\n",
      "Epoch 339/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 753.83batch/s, loss=119.63041]\n",
      "Epoch 340/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.25batch/s, loss=101.41615]\n",
      "Epoch 340/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 261.56batch/s, loss=119.47064]\n",
      "Epoch 341/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 88.11batch/s, loss=101.20735]\n",
      "Epoch 341/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 237.97batch/s, loss=119.67421]\n",
      "Epoch 342/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.25batch/s, loss=101.50481]\n",
      "Epoch 342/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 243.19batch/s, loss=120.18861]\n",
      "Epoch 343/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.46batch/s, loss=100.87066]\n",
      "Epoch 343/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 219.76batch/s, loss=120.30527]\n",
      "Epoch 344/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.44batch/s, loss=100.78938]\n",
      "Epoch 344/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 521.36batch/s, loss=119.90047]\n",
      "Epoch 345/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.74batch/s, loss=101.15814]\n",
      "Epoch 345/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 457.34batch/s, loss=120.04533]\n",
      "Epoch 346/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 260.48batch/s, loss=101.70134]\n",
      "Epoch 346/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 291.80batch/s, loss=119.57191]\n",
      "Epoch 347/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 161.94batch/s, loss=100.62499]\n",
      "Epoch 347/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=119.67068]\n",
      "Epoch 348/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 135.72batch/s, loss=100.58004]\n",
      "Epoch 348/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=119.77007]\n",
      "Epoch 349/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 129.95batch/s, loss=100.32815]\n",
      "Epoch 349/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 402.33batch/s, loss=120.01444]\n",
      "Epoch 350/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.06batch/s, loss=100.91764]\n",
      "Epoch 350/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.67batch/s, loss=120.15663]\n",
      "Epoch 351/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.38batch/s, loss=100.80343]\n",
      "Epoch 351/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.55batch/s, loss=119.98040]\n",
      "Epoch 352/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 145.88batch/s, loss=101.18259]\n",
      "Epoch 352/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 263.58batch/s, loss=120.03312]\n",
      "Epoch 353/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.56batch/s, loss=101.11246]\n",
      "Epoch 353/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 180.80batch/s, loss=119.87847]\n",
      "Epoch 354/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 316.04batch/s, loss=100.72463]\n",
      "Epoch 354/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 402.45batch/s, loss=119.47071]\n",
      "Epoch 355/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 134.07batch/s, loss=101.16743]\n",
      "Epoch 355/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 460.20batch/s, loss=119.41214]\n",
      "Epoch 356/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.28batch/s, loss=101.38350]\n",
      "Epoch 356/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.97batch/s, loss=119.53709]\n",
      "Epoch 357/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.69batch/s, loss=101.24377]\n",
      "Epoch 357/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 248.74batch/s, loss=120.01281]\n",
      "Epoch 358/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.93batch/s, loss=100.90753]\n",
      "Epoch 358/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 346.61batch/s, loss=120.44485]\n",
      "Epoch 359/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.54batch/s, loss=100.86621]\n",
      "Epoch 359/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 702.56batch/s, loss=120.18285]\n",
      "Epoch 360/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.23batch/s, loss=100.95367]\n",
      "Epoch 360/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 160.14batch/s, loss=120.10895]\n",
      "Epoch 361/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.63batch/s, loss=100.83360]\n",
      "Epoch 361/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 437.36batch/s, loss=119.94298]\n",
      "Epoch 362/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.67batch/s, loss=100.70721]\n",
      "Epoch 362/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 188.69batch/s, loss=119.52542]\n",
      "Epoch 363/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 213.54batch/s, loss=100.59368]\n",
      "Epoch 363/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 203.03batch/s, loss=119.26363]\n",
      "Epoch 364/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.59batch/s, loss=100.91882]\n",
      "Epoch 364/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 417.63batch/s, loss=119.31386]\n",
      "Epoch 365/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 222.77batch/s, loss=100.71896]\n",
      "Epoch 365/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 159.72batch/s, loss=119.13840]\n",
      "Epoch 366/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.03batch/s, loss=101.37138]\n",
      "Epoch 366/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 371.90batch/s, loss=119.56592]\n",
      "Epoch 367/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.20batch/s, loss=100.63539]\n",
      "Epoch 367/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.98batch/s, loss=119.78254]\n",
      "Epoch 368/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.01batch/s, loss=100.82080]\n",
      "Epoch 368/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 289.24batch/s, loss=120.22940]\n",
      "Epoch 369/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.53batch/s, loss=100.89093]\n",
      "Epoch 369/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 345.27batch/s, loss=120.15701]\n",
      "Epoch 370/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.90batch/s, loss=100.96609]\n",
      "Epoch 370/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.44batch/s, loss=119.81546]\n",
      "Epoch 371/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 204.21batch/s, loss=100.62437]\n",
      "Epoch 371/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 571.43batch/s, loss=119.77014]\n",
      "Epoch 372/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.51batch/s, loss=101.17476]\n",
      "Epoch 372/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=119.56383]\n",
      "Epoch 373/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.53batch/s, loss=100.64949]\n",
      "Epoch 373/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.91batch/s, loss=119.27860]\n",
      "Epoch 374/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 105.44batch/s, loss=101.21009]\n",
      "Epoch 374/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 296.69batch/s, loss=119.34032]\n",
      "Epoch 375/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.70batch/s, loss=101.37477]\n",
      "Epoch 375/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 370.69batch/s, loss=119.20606]\n",
      "Epoch 376/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.89batch/s, loss=100.72945]\n",
      "Epoch 376/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1124.48batch/s, loss=119.48086]\n",
      "Epoch 377/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.23batch/s, loss=100.79554]\n",
      "Epoch 377/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 404.62batch/s, loss=119.66634]\n",
      "Epoch 378/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 204.30batch/s, loss=100.71188]\n",
      "Epoch 378/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.51batch/s, loss=119.61543]\n",
      "Epoch 379/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 274.85batch/s, loss=101.80504]\n",
      "Epoch 379/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 314.58batch/s, loss=120.19527]\n",
      "Epoch 380/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.37batch/s, loss=100.92402]\n",
      "Epoch 380/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 347.90batch/s, loss=120.02949]\n",
      "Epoch 381/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 439.65batch/s, loss=100.51046]\n",
      "Epoch 381/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 859.14batch/s, loss=119.60074]\n",
      "Epoch 382/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.12batch/s, loss=100.52490]\n",
      "Epoch 382/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=119.31450]\n",
      "Epoch 383/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 130.44batch/s, loss=100.47997]\n",
      "Epoch 383/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 465.98batch/s, loss=119.37357]\n",
      "Epoch 384/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.49batch/s, loss=100.64561]\n",
      "Epoch 384/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 495.84batch/s, loss=119.20242]\n",
      "Epoch 385/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 161.51batch/s, loss=100.58731]\n",
      "Epoch 385/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 324.49batch/s, loss=119.02978]\n",
      "Epoch 386/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 144.13batch/s, loss=101.05450]\n",
      "Epoch 386/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 808.00batch/s, loss=119.32030]\n",
      "Epoch 387/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.71batch/s, loss=100.32059]\n",
      "Epoch 387/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 370.39batch/s, loss=119.48463]\n",
      "Epoch 388/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 186.75batch/s, loss=100.53067]\n",
      "Epoch 388/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 502.97batch/s, loss=119.42894]\n",
      "Epoch 389/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.65batch/s, loss=100.68057]\n",
      "Epoch 389/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 292.43batch/s, loss=119.52470]\n",
      "Epoch 390/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.43batch/s, loss=100.41656]\n",
      "Epoch 390/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 451.34batch/s, loss=119.58431]\n",
      "Epoch 391/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 224.62batch/s, loss=100.11513]\n",
      "Epoch 391/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=119.54768]\n",
      "Epoch 392/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.75batch/s, loss=100.61829]\n",
      "Epoch 392/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 270.37batch/s, loss=119.51866]\n",
      "Epoch 393/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.18batch/s, loss=100.43278]\n",
      "Epoch 393/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 325.01batch/s, loss=119.51126]\n",
      "Epoch 394/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.47batch/s, loss=100.31124]\n",
      "Epoch 394/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 268.85batch/s, loss=119.39992]\n",
      "Epoch 395/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.01batch/s, loss=100.74296]\n",
      "Epoch 395/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 481.38batch/s, loss=119.37840]\n",
      "Epoch 396/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.25batch/s, loss=100.79992]\n",
      "Epoch 396/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 358.12batch/s, loss=119.10123]\n",
      "Epoch 397/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 270.17batch/s, loss=100.41580]\n",
      "Epoch 397/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 322.12batch/s, loss=119.06226]\n",
      "Epoch 398/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.98batch/s, loss=100.39907]\n",
      "Epoch 398/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=119.27873]\n",
      "Epoch 399/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 123.10batch/s, loss=100.75662]\n",
      "Epoch 399/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.70batch/s, loss=119.42154]\n",
      "Epoch 400/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.49batch/s, loss=100.23126]\n",
      "Epoch 400/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 220.20batch/s, loss=119.38646]\n",
      "Epoch 401/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 133.14batch/s, loss=100.51959]\n",
      "Epoch 401/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 230.28batch/s, loss=119.42767]\n",
      "Epoch 402/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 114.43batch/s, loss=100.93733]\n",
      "Epoch 402/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 420.23batch/s, loss=119.72292]\n",
      "Epoch 403/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.53batch/s, loss=100.60558]\n",
      "Epoch 403/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 492.40batch/s, loss=119.66145]\n",
      "Epoch 404/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.17batch/s, loss=100.56919]\n",
      "Epoch 404/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 668.20batch/s, loss=119.54707]\n",
      "Epoch 405/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.98batch/s, loss=100.14896]\n",
      "Epoch 405/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.49batch/s, loss=119.16535]\n",
      "Epoch 406/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.90batch/s, loss=100.87455]\n",
      "Epoch 406/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 398.43batch/s, loss=118.79579]\n",
      "Epoch 407/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.42batch/s, loss=100.69197]\n",
      "Epoch 407/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 307.14batch/s, loss=118.73282]\n",
      "Epoch 408/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.59batch/s, loss=100.53415]\n",
      "Epoch 408/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 314.70batch/s, loss=119.05498]\n",
      "Epoch 409/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 196.17batch/s, loss=100.44801]\n",
      "Epoch 409/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 244.24batch/s, loss=119.04782]\n",
      "Epoch 410/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.05batch/s, loss=100.67626]\n",
      "Epoch 410/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 144.47batch/s, loss=119.52436]\n",
      "Epoch 411/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.46batch/s, loss=100.85669]\n",
      "Epoch 411/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 146.40batch/s, loss=119.50373]\n",
      "Epoch 412/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.44batch/s, loss=100.21983]\n",
      "Epoch 412/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 212.20batch/s, loss=119.29603]\n",
      "Epoch 413/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.46batch/s, loss=100.27195]\n",
      "Epoch 413/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 2962.08batch/s, loss=118.92818]\n",
      "Epoch 414/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 207.24batch/s, loss=100.30475]\n",
      "Epoch 414/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=118.79288]\n",
      "Epoch 415/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.25batch/s, loss=100.51015]\n",
      "Epoch 415/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1655.21batch/s, loss=118.65955]\n",
      "Epoch 416/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 234.86batch/s, loss=100.29940]\n",
      "Epoch 416/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 156.50batch/s, loss=118.46766]\n",
      "Epoch 417/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 157.85batch/s, loss=100.36403]\n",
      "Epoch 417/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 448.30batch/s, loss=118.65999]\n",
      "Epoch 418/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 376.97batch/s, loss=100.21534]\n",
      "Epoch 418/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.84batch/s, loss=118.89324]\n",
      "Epoch 419/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.72batch/s, loss=100.15788]\n",
      "Epoch 419/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 222.49batch/s, loss=119.07996]\n",
      "Epoch 420/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.18batch/s, loss=100.21834]\n",
      "Epoch 420/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 338.96batch/s, loss=118.74728]\n",
      "Epoch 421/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.36batch/s, loss=99.99819]\n",
      "Epoch 421/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 209.98batch/s, loss=118.59224]\n",
      "Epoch 422/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 141.53batch/s, loss=100.36333]\n",
      "Epoch 422/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 300.45batch/s, loss=118.73350]\n",
      "Epoch 423/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.26batch/s, loss=100.23113]\n",
      "Epoch 423/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 258.24batch/s, loss=118.34496]\n",
      "Epoch 424/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.39batch/s, loss=100.12008]\n",
      "Epoch 424/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 467.12batch/s, loss=118.59640]\n",
      "Epoch 425/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.51batch/s, loss=100.46892]\n",
      "Epoch 425/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 378.99batch/s, loss=118.40841]\n",
      "Epoch 426/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 234.99batch/s, loss=99.28637]\n",
      "Epoch 426/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 311.94batch/s, loss=118.46467]\n",
      "Epoch 427/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 251.48batch/s, loss=99.56570]\n",
      "Epoch 427/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 254.42batch/s, loss=118.47398]\n",
      "Epoch 428/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.04batch/s, loss=99.87752]\n",
      "Epoch 428/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=118.66633]\n",
      "Epoch 429/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.01batch/s, loss=99.78129]\n",
      "Epoch 429/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 317.01batch/s, loss=118.56534]\n",
      "Epoch 430/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.71batch/s, loss=99.68899]\n",
      "Epoch 430/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=118.32679]\n",
      "Epoch 431/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.90batch/s, loss=100.34979]\n",
      "Epoch 431/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 280.35batch/s, loss=118.55824]\n",
      "Epoch 432/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.26batch/s, loss=99.74971]\n",
      "Epoch 432/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 340.28batch/s, loss=118.22073]\n",
      "Epoch 433/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.72batch/s, loss=99.87236]\n",
      "Epoch 433/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 266.85batch/s, loss=117.91181]\n",
      "Epoch 434/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 245.24batch/s, loss=99.37530]\n",
      "Epoch 434/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 153.50batch/s, loss=117.42072]\n",
      "Epoch 435/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 220.12batch/s, loss=99.48958]\n",
      "Epoch 435/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 328.84batch/s, loss=117.52528]\n",
      "Epoch 436/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.87batch/s, loss=99.46907]\n",
      "Epoch 436/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 408.24batch/s, loss=117.57240]\n",
      "Epoch 437/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.65batch/s, loss=99.46513]\n",
      "Epoch 437/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=117.87503]\n",
      "Epoch 438/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 118.35batch/s, loss=99.43390]\n",
      "Epoch 438/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=117.71664]\n",
      "Epoch 439/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.91batch/s, loss=99.07461]\n",
      "Epoch 439/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 349.29batch/s, loss=117.41511]\n",
      "Epoch 440/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.03batch/s, loss=99.53926]\n",
      "Epoch 440/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 411.85batch/s, loss=117.48907]\n",
      "Epoch 441/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 280.65batch/s, loss=98.96220]\n",
      "Epoch 441/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 423.88batch/s, loss=117.04192]\n",
      "Epoch 442/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.45batch/s, loss=98.91979]\n",
      "Epoch 442/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 615.81batch/s, loss=116.74458]\n",
      "Epoch 443/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 126.48batch/s, loss=97.79295]\n",
      "Epoch 443/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 426.81batch/s, loss=116.46130]\n",
      "Epoch 444/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.74batch/s, loss=98.68711]\n",
      "Epoch 444/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 889.00batch/s, loss=116.63439]\n",
      "Epoch 445/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.69batch/s, loss=98.78938]\n",
      "Epoch 445/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=116.41727]\n",
      "Epoch 446/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.66batch/s, loss=97.84893]\n",
      "Epoch 446/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 741.17batch/s, loss=116.05798]\n",
      "Epoch 447/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.93batch/s, loss=97.92977]\n",
      "Epoch 447/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 324.08batch/s, loss=115.97416]\n",
      "Epoch 448/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.32batch/s, loss=97.56086]\n",
      "Epoch 448/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 449.94batch/s, loss=115.72605]\n",
      "Epoch 449/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.12batch/s, loss=97.69204]\n",
      "Epoch 449/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 356.84batch/s, loss=115.74388]\n",
      "Epoch 450/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.47batch/s, loss=97.15513]\n",
      "Epoch 450/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 425.64batch/s, loss=115.44684]\n",
      "Epoch 451/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.72batch/s, loss=97.47748]\n",
      "Epoch 451/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.19batch/s, loss=115.46292]\n",
      "Epoch 452/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 149.77batch/s, loss=96.52702]\n",
      "Epoch 452/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 444.12batch/s, loss=114.78629]\n",
      "Epoch 453/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 144.19batch/s, loss=96.35556]\n",
      "Epoch 453/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 396.62batch/s, loss=113.85671]\n",
      "Epoch 454/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 208.40batch/s, loss=95.94501]\n",
      "Epoch 454/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 371.21batch/s, loss=113.42960]\n",
      "Epoch 455/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.65batch/s, loss=95.67824]\n",
      "Epoch 455/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 450.27batch/s, loss=113.11799]\n",
      "Epoch 456/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 226.71batch/s, loss=95.35599]\n",
      "Epoch 456/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 142.37batch/s, loss=112.89694]\n",
      "Epoch 457/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 118.27batch/s, loss=95.09732]\n",
      "Epoch 457/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.80batch/s, loss=112.92751]\n",
      "Epoch 458/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 196.21batch/s, loss=95.03881]\n",
      "Epoch 458/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1000.55batch/s, loss=112.00857]\n",
      "Epoch 459/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.29batch/s, loss=94.55414]\n",
      "Epoch 459/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 419.22batch/s, loss=111.47974]\n",
      "Epoch 460/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.68batch/s, loss=93.67056]\n",
      "Epoch 460/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 262.92batch/s, loss=110.54474]\n",
      "Epoch 461/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 142.65batch/s, loss=93.59221]\n",
      "Epoch 461/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1033.84batch/s, loss=109.88786]\n",
      "Epoch 462/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.36batch/s, loss=92.95766]\n",
      "Epoch 462/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 260.81batch/s, loss=109.61676]\n",
      "Epoch 463/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.00batch/s, loss=92.92509]\n",
      "Epoch 463/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 347.50batch/s, loss=109.86954]\n",
      "Epoch 464/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 151.65batch/s, loss=92.39487]\n",
      "Epoch 464/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 335.14batch/s, loss=109.56319]\n",
      "Epoch 465/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 143.07batch/s, loss=91.72219]\n",
      "Epoch 465/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 277.47batch/s, loss=108.02847]\n",
      "Epoch 466/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.36batch/s, loss=91.14748]\n",
      "Epoch 466/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1169.31batch/s, loss=106.80165]\n",
      "Epoch 467/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.85batch/s, loss=90.67460]\n",
      "Epoch 467/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 448.01batch/s, loss=105.54478]\n",
      "Epoch 468/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.65batch/s, loss=90.07692]\n",
      "Epoch 468/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 569.49batch/s, loss=105.25403]\n",
      "Epoch 469/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.50batch/s, loss=88.61423]\n",
      "Epoch 469/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.79batch/s, loss=104.83300]\n",
      "Epoch 470/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.42batch/s, loss=88.15030]\n",
      "Epoch 470/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 347.44batch/s, loss=104.06386]\n",
      "Epoch 471/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.43batch/s, loss=87.10807]\n",
      "Epoch 471/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 472.92batch/s, loss=102.73461]\n",
      "Epoch 472/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.47batch/s, loss=86.23989]\n",
      "Epoch 472/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 362.11batch/s, loss=101.73401]\n",
      "Epoch 473/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.73batch/s, loss=85.81419]\n",
      "Epoch 473/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 443.04batch/s, loss=100.81477]\n",
      "Epoch 474/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.42batch/s, loss=84.98881]\n",
      "Epoch 474/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=99.79721]\n",
      "Epoch 475/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 157.53batch/s, loss=83.61792]\n",
      "Epoch 475/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 340.20batch/s, loss=98.27477]\n",
      "Epoch 476/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.90batch/s, loss=82.80185]\n",
      "Epoch 476/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.19batch/s, loss=96.83994]\n",
      "Epoch 477/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.15batch/s, loss=81.65279]\n",
      "Epoch 477/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 741.17batch/s, loss=95.85870]\n",
      "Epoch 478/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 129.32batch/s, loss=80.24882]\n",
      "Epoch 478/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 226.50batch/s, loss=94.79772]\n",
      "Epoch 479/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.42batch/s, loss=79.18197]\n",
      "Epoch 479/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 509.08batch/s, loss=93.78615]\n",
      "Epoch 480/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.88batch/s, loss=78.53474]\n",
      "Epoch 480/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=92.22787]\n",
      "Epoch 481/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 164.88batch/s, loss=76.79776]\n",
      "Epoch 481/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=90.79835]\n",
      "Epoch 482/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.70batch/s, loss=75.56717]\n",
      "Epoch 482/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 3045.97batch/s, loss=88.63853]\n",
      "Epoch 483/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.32batch/s, loss=74.11415]\n",
      "Epoch 483/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.26batch/s, loss=86.42780]\n",
      "Epoch 484/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.11batch/s, loss=72.05836]\n",
      "Epoch 484/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 488.56batch/s, loss=84.38248]\n",
      "Epoch 485/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 267.95batch/s, loss=70.46432]\n",
      "Epoch 485/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 399.23batch/s, loss=82.25391]\n",
      "Epoch 486/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.07batch/s, loss=68.73767]\n",
      "Epoch 486/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 273.57batch/s, loss=80.84096]\n",
      "Epoch 487/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 135.52batch/s, loss=66.77585]\n",
      "Epoch 487/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=78.20295]\n",
      "Epoch 488/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.39batch/s, loss=64.47822]\n",
      "Epoch 488/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 836.35batch/s, loss=74.73913]\n",
      "Epoch 489/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.87batch/s, loss=62.07588]\n",
      "Epoch 489/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 547.27batch/s, loss=71.50527]\n",
      "Epoch 490/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.42batch/s, loss=59.27668]\n",
      "Epoch 490/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.15batch/s, loss=68.42413]\n",
      "Epoch 491/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.90batch/s, loss=56.15547]\n",
      "Epoch 491/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=66.77916]\n",
      "Epoch 492/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 230.15batch/s, loss=53.74156]\n",
      "Epoch 492/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.80batch/s, loss=61.40797]\n",
      "Epoch 493/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.11batch/s, loss=49.90006]\n",
      "Epoch 493/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.33batch/s, loss=57.05754]\n",
      "Epoch 494/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 99.62batch/s, loss=47.07697]\n",
      "Epoch 494/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 378.72batch/s, loss=52.90362]\n",
      "Epoch 495/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 90.83batch/s, loss=42.95130]\n",
      "Epoch 495/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 204.50batch/s, loss=49.90682]\n",
      "Epoch 496/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 88.97batch/s, loss=40.03681]\n",
      "Epoch 496/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 532.20batch/s, loss=45.74364]\n",
      "Epoch 497/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 95.69batch/s, loss=36.26194]\n",
      "Epoch 497/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 390.42batch/s, loss=40.90240]\n",
      "Epoch 498/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 82.29batch/s, loss=32.56110]\n",
      "Epoch 498/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.01batch/s, loss=36.38069]\n",
      "Epoch 499/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 102.55batch/s, loss=28.68854]\n",
      "Epoch 499/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 203.70batch/s, loss=32.79227]\n",
      "Epoch 500/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 101.59batch/s, loss=25.49588]\n",
      "Epoch 500/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 316.81batch/s, loss=28.33582]\n",
      "Epoch 501/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 106.70batch/s, loss=22.08058]\n",
      "Epoch 501/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=24.30172]\n",
      "Epoch 502/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 80.28batch/s, loss=18.65002]\n",
      "Epoch 502/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 148.92batch/s, loss=20.66663]\n",
      "Epoch 503/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 84.48batch/s, loss=15.47782]\n",
      "Epoch 503/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=17.00220]\n",
      "Epoch 504/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 86.24batch/s, loss=12.53934]\n",
      "Epoch 504/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.38batch/s, loss=13.73944]\n",
      "Epoch 505/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 101.39batch/s, loss=9.96701]\n",
      "Epoch 505/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=10.71679]\n",
      "Epoch 506/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 111.25batch/s, loss=7.57783]\n",
      "Epoch 506/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 260.56batch/s, loss=8.34794]\n",
      "Epoch 507/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 103.73batch/s, loss=5.75253]\n",
      "Epoch 507/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 615.72batch/s, loss=6.33184]\n",
      "Epoch 508/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 93.89batch/s, loss=4.36917]\n",
      "Epoch 508/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.31batch/s, loss=4.95496]\n",
      "Epoch 509/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 114.33batch/s, loss=3.36365]\n",
      "Epoch 509/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 310.64batch/s, loss=4.02369]\n",
      "Epoch 510/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 84.11batch/s, loss=2.78030]\n",
      "Epoch 510/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 786.04batch/s, loss=3.53048]\n",
      "Epoch 511/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 101.85batch/s, loss=2.53675]\n",
      "Epoch 511/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 261.31batch/s, loss=3.22823]\n",
      "Epoch 512/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 118.88batch/s, loss=2.53084]\n",
      "Epoch 512/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 130.48batch/s, loss=3.16726]\n",
      "Epoch 513/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 104.16batch/s, loss=2.60582]\n",
      "Epoch 513/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 275.90batch/s, loss=3.16228]\n",
      "Epoch 514/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 107.66batch/s, loss=2.66584]\n",
      "Epoch 514/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 325.52batch/s, loss=3.13105]\n",
      "Epoch 515/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 106.03batch/s, loss=2.70203]\n",
      "Epoch 515/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 130.38batch/s, loss=3.02860]\n",
      "Epoch 516/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 104.29batch/s, loss=2.59757]\n",
      "Epoch 516/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 328.68batch/s, loss=2.95300]\n",
      "Epoch 517/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.60batch/s, loss=2.49430]\n",
      "Epoch 517/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 327.73batch/s, loss=2.92057]\n",
      "Epoch 518/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 117.75batch/s, loss=2.38210]\n",
      "Epoch 518/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 299.64batch/s, loss=2.82386]\n",
      "Epoch 519/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 103.57batch/s, loss=2.35323]\n",
      "Epoch 519/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 259.23batch/s, loss=2.78268]\n",
      "Epoch 520/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 103.29batch/s, loss=2.35976]\n",
      "Epoch 520/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.74900]\n",
      "Epoch 521/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 108.01batch/s, loss=2.31715]\n",
      "Epoch 521/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 157.20batch/s, loss=2.79267]\n",
      "Epoch 522/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 100.68batch/s, loss=2.29619]\n",
      "Epoch 522/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 178.09batch/s, loss=2.82555]\n",
      "Epoch 523/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 95.67batch/s, loss=2.31125]\n",
      "Epoch 523/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 495.78batch/s, loss=2.72889]\n",
      "Epoch 524/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 98.69batch/s, loss=2.22869]\n",
      "Epoch 524/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.92batch/s, loss=2.69203]\n",
      "Epoch 525/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 102.04batch/s, loss=2.21584]\n",
      "Epoch 525/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.63671]\n",
      "Epoch 526/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 103.44batch/s, loss=2.15601]\n",
      "Epoch 526/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 555.54batch/s, loss=2.61780]\n",
      "Epoch 527/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 121.31batch/s, loss=2.14657]\n",
      "Epoch 527/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 135.89batch/s, loss=2.61669]\n",
      "Epoch 528/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 113.96batch/s, loss=2.14679]\n",
      "Epoch 528/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.58487]\n",
      "Epoch 529/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 108.46batch/s, loss=2.16768]\n",
      "Epoch 529/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 322.09batch/s, loss=2.57255]\n",
      "Epoch 530/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 82.00batch/s, loss=2.12678]\n",
      "Epoch 530/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 303.76batch/s, loss=2.55177]\n",
      "Epoch 531/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 113.08batch/s, loss=2.11343]\n",
      "Epoch 531/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 434.46batch/s, loss=2.54909]\n",
      "Epoch 532/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 104.05batch/s, loss=2.10928]\n",
      "Epoch 532/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 285.04batch/s, loss=2.50930]\n",
      "Epoch 533/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 106.11batch/s, loss=2.09577]\n",
      "Epoch 533/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 358.43batch/s, loss=2.51220]\n",
      "Epoch 534/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 97.10batch/s, loss=2.07799]\n",
      "Epoch 534/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 727.55batch/s, loss=2.50445]\n",
      "Epoch 535/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 126.07batch/s, loss=2.07996]\n",
      "Epoch 535/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 309.66batch/s, loss=2.50034]\n",
      "Epoch 536/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 104.32batch/s, loss=2.08731]\n",
      "Epoch 536/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 375.73batch/s, loss=2.50152]\n",
      "Epoch 537/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 96.87batch/s, loss=2.06736]\n",
      "Epoch 537/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 242.56batch/s, loss=2.50544]\n",
      "Epoch 538/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 102.00batch/s, loss=2.05770]\n",
      "Epoch 538/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50655]\n",
      "Epoch 539/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 83.82batch/s, loss=2.06401]\n",
      "Epoch 539/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 383.01batch/s, loss=2.48627]\n",
      "Epoch 540/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 98.25batch/s, loss=2.05189]\n",
      "Epoch 540/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 378.21batch/s, loss=2.47950]\n",
      "Epoch 541/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 110.74batch/s, loss=2.05350]\n",
      "Epoch 541/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 323.98batch/s, loss=2.47996]\n",
      "Epoch 542/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 87.13batch/s, loss=2.07369]\n",
      "Epoch 542/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 264.86batch/s, loss=2.49550]\n",
      "Epoch 543/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 106.85batch/s, loss=2.06210]\n",
      "Epoch 543/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 374.93batch/s, loss=2.49859]\n",
      "Epoch 544/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 82.41batch/s, loss=2.05803]\n",
      "Epoch 544/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 224.92batch/s, loss=2.49994]\n",
      "Epoch 545/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 96.96batch/s, loss=2.07460]\n",
      "Epoch 545/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 372.63batch/s, loss=2.49832]\n",
      "Epoch 546/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 89.46batch/s, loss=2.07657]\n",
      "Epoch 546/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 243.70batch/s, loss=2.50284]\n",
      "Epoch 547/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 105.77batch/s, loss=2.04387]\n",
      "Epoch 547/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 278.64batch/s, loss=2.50812]\n",
      "Epoch 548/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 108.27batch/s, loss=2.06358]\n",
      "Epoch 548/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.49batch/s, loss=2.50001]\n",
      "Epoch 549/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.38batch/s, loss=2.10354]\n",
      "Epoch 549/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 278.17batch/s, loss=2.49922]\n",
      "Epoch 550/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.82batch/s, loss=2.06419]\n",
      "Epoch 550/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 259.45batch/s, loss=2.47936]\n",
      "Epoch 551/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 115.18batch/s, loss=2.06974]\n",
      "Epoch 551/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 191.15batch/s, loss=2.51713]\n",
      "Epoch 552/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 281.02batch/s, loss=2.06403]\n",
      "Epoch 552/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 360.27batch/s, loss=2.50603]\n",
      "Epoch 553/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.36batch/s, loss=2.06389]\n",
      "Epoch 553/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.43batch/s, loss=2.47893]\n",
      "Epoch 554/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.59batch/s, loss=2.05827]\n",
      "Epoch 554/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 536.22batch/s, loss=2.49905]\n",
      "Epoch 555/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.11batch/s, loss=2.04472]\n",
      "Epoch 555/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.16batch/s, loss=2.51824]\n",
      "Epoch 556/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.87batch/s, loss=2.04243]\n",
      "Epoch 556/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 252.99batch/s, loss=2.52976]\n",
      "Epoch 557/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.17batch/s, loss=2.06287]\n",
      "Epoch 557/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.01batch/s, loss=2.48934]\n",
      "Epoch 558/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 390.31batch/s, loss=2.06145]\n",
      "Epoch 558/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 491.65batch/s, loss=2.48070]\n",
      "Epoch 559/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 230.71batch/s, loss=2.03356]\n",
      "Epoch 559/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 272.73batch/s, loss=2.51779]\n",
      "Epoch 560/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.63batch/s, loss=2.05517]\n",
      "Epoch 560/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 157.24batch/s, loss=2.52588]\n",
      "Epoch 561/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.22batch/s, loss=2.05139]\n",
      "Epoch 561/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 250.66batch/s, loss=2.50586]\n",
      "Epoch 562/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 238.61batch/s, loss=2.04718]\n",
      "Epoch 562/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 142.15batch/s, loss=2.49462]\n",
      "Epoch 563/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 111.45batch/s, loss=2.03570]\n",
      "Epoch 563/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 238.60batch/s, loss=2.51604]\n",
      "Epoch 564/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.68batch/s, loss=2.04446]\n",
      "Epoch 564/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 321.53batch/s, loss=2.49613]\n",
      "Epoch 565/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.39batch/s, loss=2.03806]\n",
      "Epoch 565/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.48120]\n",
      "Epoch 566/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 118.61batch/s, loss=2.04288]\n",
      "Epoch 566/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.85batch/s, loss=2.49229]\n",
      "Epoch 567/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.33batch/s, loss=2.05305]\n",
      "Epoch 567/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.52005]\n",
      "Epoch 568/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.68batch/s, loss=2.08014]\n",
      "Epoch 568/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.75batch/s, loss=2.51500]\n",
      "Epoch 569/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 135.32batch/s, loss=2.04817]\n",
      "Epoch 569/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.73batch/s, loss=2.53838]\n",
      "Epoch 570/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.06batch/s, loss=2.04313]\n",
      "Epoch 570/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.48728]\n",
      "Epoch 571/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 122.53batch/s, loss=2.07024]\n",
      "Epoch 571/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.20batch/s, loss=2.52068]\n",
      "Epoch 572/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.31batch/s, loss=2.03646]\n",
      "Epoch 572/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 194.41batch/s, loss=2.49493]\n",
      "Epoch 573/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.15batch/s, loss=2.04874]\n",
      "Epoch 573/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 278.64batch/s, loss=2.48926]\n",
      "Epoch 574/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.15batch/s, loss=2.05317]\n",
      "Epoch 574/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 363.77batch/s, loss=2.52064]\n",
      "Epoch 575/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 147.68batch/s, loss=2.03243]\n",
      "Epoch 575/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 490.85batch/s, loss=2.49031]\n",
      "Epoch 576/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 143.66batch/s, loss=2.01174]\n",
      "Epoch 576/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 411.77batch/s, loss=2.49806]\n",
      "Epoch 577/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.93batch/s, loss=2.03521]\n",
      "Epoch 577/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 751.80batch/s, loss=2.49265]\n",
      "Epoch 578/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.59batch/s, loss=2.03381]\n",
      "Epoch 578/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 482.66batch/s, loss=2.49310]\n",
      "Epoch 579/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.02batch/s, loss=2.04461]\n",
      "Epoch 579/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 312.15batch/s, loss=2.50042]\n",
      "Epoch 580/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.74batch/s, loss=2.03259]\n",
      "Epoch 580/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 287.48batch/s, loss=2.49449]\n",
      "Epoch 581/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.13batch/s, loss=2.02763]\n",
      "Epoch 581/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 276.25batch/s, loss=2.50772]\n",
      "Epoch 582/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.24batch/s, loss=2.06741]\n",
      "Epoch 582/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.08batch/s, loss=2.52097]\n",
      "Epoch 583/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 164.92batch/s, loss=2.04493]\n",
      "Epoch 583/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 475.87batch/s, loss=2.49054]\n",
      "Epoch 584/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 157.91batch/s, loss=2.03867]\n",
      "Epoch 584/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 257.95batch/s, loss=2.51538]\n",
      "Epoch 585/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.17batch/s, loss=2.03762]\n",
      "Epoch 585/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 457.69batch/s, loss=2.49692]\n",
      "Epoch 586/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.18batch/s, loss=2.06775]\n",
      "Epoch 586/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 390.06batch/s, loss=2.54283]\n",
      "Epoch 587/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.28batch/s, loss=2.06445]\n",
      "Epoch 587/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 2748.56batch/s, loss=2.50324]\n",
      "Epoch 588/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 125.80batch/s, loss=2.05053]\n",
      "Epoch 588/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 315.72batch/s, loss=2.52594]\n",
      "Epoch 589/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 159.53batch/s, loss=2.04934]\n",
      "Epoch 589/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 229.96batch/s, loss=2.50619]\n",
      "Epoch 590/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 149.68batch/s, loss=2.04555]\n",
      "Epoch 590/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.49batch/s, loss=2.50401]\n",
      "Epoch 591/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 114.91batch/s, loss=2.03537]\n",
      "Epoch 591/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 2613.27batch/s, loss=2.50179]\n",
      "Epoch 592/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 126.53batch/s, loss=2.02709]\n",
      "Epoch 592/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.78batch/s, loss=2.48550]\n",
      "Epoch 593/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.22batch/s, loss=2.03118]\n",
      "Epoch 593/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.48510]\n",
      "Epoch 594/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.83batch/s, loss=2.02500]\n",
      "Epoch 594/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50064]\n",
      "Epoch 595/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.77batch/s, loss=2.02866]\n",
      "Epoch 595/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 201.74batch/s, loss=2.52080]\n",
      "Epoch 596/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.30batch/s, loss=2.03630]\n",
      "Epoch 596/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 266.32batch/s, loss=2.49059]\n",
      "Epoch 597/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 134.93batch/s, loss=2.02189]\n",
      "Epoch 597/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 636.75batch/s, loss=2.52387]\n",
      "Epoch 598/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 225.99batch/s, loss=2.02877]\n",
      "Epoch 598/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.49179]\n",
      "Epoch 599/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 118.32batch/s, loss=2.02283]\n",
      "Epoch 599/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 461.78batch/s, loss=2.50441]\n",
      "Epoch 600/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 240.86batch/s, loss=2.03586]\n",
      "Epoch 600/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.54batch/s, loss=2.49462]\n",
      "Epoch 601/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 343.65batch/s, loss=2.03212]\n",
      "Epoch 601/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 126.67batch/s, loss=2.50750]\n",
      "Epoch 602/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 212.24batch/s, loss=2.01736]\n",
      "Epoch 602/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 346.04batch/s, loss=2.52972]\n",
      "Epoch 603/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.30batch/s, loss=2.03668]\n",
      "Epoch 603/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 653.83batch/s, loss=2.50981]\n",
      "Epoch 604/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 140.08batch/s, loss=2.06470]\n",
      "Epoch 604/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.51833]\n",
      "Epoch 605/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.20batch/s, loss=2.03832]\n",
      "Epoch 605/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.06batch/s, loss=2.50394]\n",
      "Epoch 606/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.26batch/s, loss=2.05878]\n",
      "Epoch 606/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 347.70batch/s, loss=2.52806]\n",
      "Epoch 607/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.06batch/s, loss=2.02552]\n",
      "Epoch 607/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.14batch/s, loss=2.54616]\n",
      "Epoch 608/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 102.91batch/s, loss=2.04354]\n",
      "Epoch 608/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 244.82batch/s, loss=2.54763]\n",
      "Epoch 609/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 151.38batch/s, loss=2.06130]\n",
      "Epoch 609/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 298.55batch/s, loss=2.51378]\n",
      "Epoch 610/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 138.09batch/s, loss=2.05905]\n",
      "Epoch 610/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 622.12batch/s, loss=2.51381]\n",
      "Epoch 611/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.73batch/s, loss=2.02216]\n",
      "Epoch 611/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 357.21batch/s, loss=2.50535]\n",
      "Epoch 612/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 116.58batch/s, loss=2.01923]\n",
      "Epoch 612/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 475.92batch/s, loss=2.51835]\n",
      "Epoch 613/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.40batch/s, loss=2.05631]\n",
      "Epoch 613/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 251.28batch/s, loss=2.51116]\n",
      "Epoch 614/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.75batch/s, loss=2.03451]\n",
      "Epoch 614/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 326.71batch/s, loss=2.49590]\n",
      "Epoch 615/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.25batch/s, loss=2.02353]\n",
      "Epoch 615/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 495.25batch/s, loss=2.51247]\n",
      "Epoch 616/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.03batch/s, loss=2.03772]\n",
      "Epoch 616/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 383.50batch/s, loss=2.49102]\n",
      "Epoch 617/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 162.97batch/s, loss=2.01221]\n",
      "Epoch 617/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 398.21batch/s, loss=2.52055]\n",
      "Epoch 618/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 331.33batch/s, loss=2.02004]\n",
      "Epoch 618/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 363.30batch/s, loss=2.50702]\n",
      "Epoch 619/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.82batch/s, loss=2.02743]\n",
      "Epoch 619/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 805.51batch/s, loss=2.52429]\n",
      "Epoch 620/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.46batch/s, loss=2.03127]\n",
      "Epoch 620/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.38batch/s, loss=2.50129]\n",
      "Epoch 621/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.78batch/s, loss=2.04450]\n",
      "Epoch 621/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 799.07batch/s, loss=2.49983]\n",
      "Epoch 622/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 196.22batch/s, loss=2.03570]\n",
      "Epoch 622/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 324.03batch/s, loss=2.52840]\n",
      "Epoch 623/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 278.03batch/s, loss=2.02790]\n",
      "Epoch 623/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.96batch/s, loss=2.54003]\n",
      "Epoch 624/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 392.19batch/s, loss=2.01574]\n",
      "Epoch 624/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 549.71batch/s, loss=2.53639]\n",
      "Epoch 625/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 214.93batch/s, loss=2.04005]\n",
      "Epoch 625/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.20batch/s, loss=2.51136]\n",
      "Epoch 626/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 258.67batch/s, loss=2.03698]\n",
      "Epoch 626/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 156.63batch/s, loss=2.50175]\n",
      "Epoch 627/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.10batch/s, loss=2.06136]\n",
      "Epoch 627/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 374.06batch/s, loss=2.50067]\n",
      "Epoch 628/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.90batch/s, loss=2.04450]\n",
      "Epoch 628/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 223.40batch/s, loss=2.54989]\n",
      "Epoch 629/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.13batch/s, loss=2.02597]\n",
      "Epoch 629/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 340.61batch/s, loss=2.54568]\n",
      "Epoch 630/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 186.70batch/s, loss=2.05181]\n",
      "Epoch 630/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 414.66batch/s, loss=2.51428]\n",
      "Epoch 631/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.57batch/s, loss=2.04442]\n",
      "Epoch 631/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.90batch/s, loss=2.51989]\n",
      "Epoch 632/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 225.07batch/s, loss=2.01764]\n",
      "Epoch 632/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 407.73batch/s, loss=2.52201]\n",
      "Epoch 633/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.02batch/s, loss=2.03168]\n",
      "Epoch 633/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.06batch/s, loss=2.52682]\n",
      "Epoch 634/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.62batch/s, loss=2.03915]\n",
      "Epoch 634/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.28batch/s, loss=2.50435]\n",
      "Epoch 635/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 218.24batch/s, loss=2.03217]\n",
      "Epoch 635/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.12batch/s, loss=2.49837]\n",
      "Epoch 636/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.07batch/s, loss=2.03004]\n",
      "Epoch 636/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 354.58batch/s, loss=2.51288]\n",
      "Epoch 637/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.23batch/s, loss=2.04522]\n",
      "Epoch 637/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.25batch/s, loss=2.49291]\n",
      "Epoch 638/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 145.04batch/s, loss=2.01840]\n",
      "Epoch 638/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 266.66batch/s, loss=2.51009]\n",
      "Epoch 639/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.78batch/s, loss=2.02825]\n",
      "Epoch 639/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 249.99batch/s, loss=2.52228]\n",
      "Epoch 640/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.67batch/s, loss=2.03760]\n",
      "Epoch 640/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.86batch/s, loss=2.51824]\n",
      "Epoch 641/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 281.15batch/s, loss=2.05516]\n",
      "Epoch 641/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.73batch/s, loss=2.51715]\n",
      "Epoch 642/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.89batch/s, loss=2.03871]\n",
      "Epoch 642/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.20batch/s, loss=2.49502]\n",
      "Epoch 643/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 151.98batch/s, loss=2.02660]\n",
      "Epoch 643/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 200.63batch/s, loss=2.49788]\n",
      "Epoch 644/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 219.63batch/s, loss=2.03599]\n",
      "Epoch 644/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.25batch/s, loss=2.50650]\n",
      "Epoch 645/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 206.20batch/s, loss=2.02480]\n",
      "Epoch 645/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 968.66batch/s, loss=2.52449]\n",
      "Epoch 646/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 144.46batch/s, loss=2.04811]\n",
      "Epoch 646/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 436.09batch/s, loss=2.53453]\n",
      "Epoch 647/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.45batch/s, loss=2.03091]\n",
      "Epoch 647/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.49batch/s, loss=2.50589]\n",
      "Epoch 648/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.97batch/s, loss=2.05362]\n",
      "Epoch 648/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 415.52batch/s, loss=2.50870]\n",
      "Epoch 649/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 298.51batch/s, loss=2.03252]\n",
      "Epoch 649/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 328.06batch/s, loss=2.49986]\n",
      "Epoch 650/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 164.23batch/s, loss=2.04256]\n",
      "Epoch 650/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 344.64batch/s, loss=2.54229]\n",
      "Epoch 651/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 60.58batch/s, loss=2.04914]\n",
      "Epoch 651/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 145.42batch/s, loss=2.50467]\n",
      "Epoch 652/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 143.50batch/s, loss=2.03629]\n",
      "Epoch 652/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 484.22batch/s, loss=2.50393]\n",
      "Epoch 653/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.24batch/s, loss=2.03678]\n",
      "Epoch 653/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 252.14batch/s, loss=2.50818]\n",
      "Epoch 654/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 211.62batch/s, loss=2.02654]\n",
      "Epoch 654/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 149.56batch/s, loss=2.51439]\n",
      "Epoch 655/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 285.27batch/s, loss=2.03432]\n",
      "Epoch 655/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 129.11batch/s, loss=2.52574]\n",
      "Epoch 656/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.26batch/s, loss=2.02196]\n",
      "Epoch 656/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 303.50batch/s, loss=2.49739]\n",
      "Epoch 657/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.90batch/s, loss=2.02533]\n",
      "Epoch 657/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 430.80batch/s, loss=2.50922]\n",
      "Epoch 658/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.32batch/s, loss=2.02945]\n",
      "Epoch 658/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.51386]\n",
      "Epoch 659/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 132.67batch/s, loss=2.01510]\n",
      "Epoch 659/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 657.31batch/s, loss=2.49763]\n",
      "Epoch 660/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 488.08batch/s, loss=2.02548]\n",
      "Epoch 660/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.95batch/s, loss=2.51643]\n",
      "Epoch 661/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.84batch/s, loss=2.03504]\n",
      "Epoch 661/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 385.93batch/s, loss=2.50309]\n",
      "Epoch 662/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.43batch/s, loss=2.01053]\n",
      "Epoch 662/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.72batch/s, loss=2.48853]\n",
      "Epoch 663/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 124.99batch/s, loss=2.02504]\n",
      "Epoch 663/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 336.89batch/s, loss=2.50311]\n",
      "Epoch 664/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.54batch/s, loss=2.02345]\n",
      "Epoch 664/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 357.97batch/s, loss=2.51378]\n",
      "Epoch 665/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.25batch/s, loss=2.02017]\n",
      "Epoch 665/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 235.52batch/s, loss=2.50188]\n",
      "Epoch 666/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.92batch/s, loss=2.00478]\n",
      "Epoch 666/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 488.16batch/s, loss=2.49691]\n",
      "Epoch 667/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 186.55batch/s, loss=2.03292]\n",
      "Epoch 667/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 435.50batch/s, loss=2.49708]\n",
      "Epoch 668/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.26batch/s, loss=2.00699]\n",
      "Epoch 668/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 105.92batch/s, loss=2.49438]\n",
      "Epoch 669/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.14batch/s, loss=2.01540]\n",
      "Epoch 669/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 312.45batch/s, loss=2.51618]\n",
      "Epoch 670/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.25batch/s, loss=2.02331]\n",
      "Epoch 670/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 544.22batch/s, loss=2.50753]\n",
      "Epoch 671/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 141.53batch/s, loss=2.02174]\n",
      "Epoch 671/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 328.04batch/s, loss=2.52223]\n",
      "Epoch 672/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.04batch/s, loss=2.02678]\n",
      "Epoch 672/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.49710]\n",
      "Epoch 673/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 109.27batch/s, loss=2.03753]\n",
      "Epoch 673/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 473.50batch/s, loss=2.56055]\n",
      "Epoch 674/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.66batch/s, loss=2.03559]\n",
      "Epoch 674/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 293.29batch/s, loss=2.51657]\n",
      "Epoch 675/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.98batch/s, loss=2.04338]\n",
      "Epoch 675/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.37batch/s, loss=2.52811]\n",
      "Epoch 676/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.83batch/s, loss=2.02984]\n",
      "Epoch 676/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.85batch/s, loss=2.50819]\n",
      "Epoch 677/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.15batch/s, loss=2.04744]\n",
      "Epoch 677/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 467.85batch/s, loss=2.52226]\n",
      "Epoch 678/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.33batch/s, loss=2.03004]\n",
      "Epoch 678/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 489.13batch/s, loss=2.51607]\n",
      "Epoch 679/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.85batch/s, loss=2.04612]\n",
      "Epoch 679/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 244.61batch/s, loss=2.53630]\n",
      "Epoch 680/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.73batch/s, loss=2.03663]\n",
      "Epoch 680/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 514.45batch/s, loss=2.51197]\n",
      "Epoch 681/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.94batch/s, loss=2.01790]\n",
      "Epoch 681/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 248.88batch/s, loss=2.50322]\n",
      "Epoch 682/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.90batch/s, loss=2.01913]\n",
      "Epoch 682/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 290.08batch/s, loss=2.52686]\n",
      "Epoch 683/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 205.88batch/s, loss=2.01746]\n",
      "Epoch 683/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.20batch/s, loss=2.50196]\n",
      "Epoch 684/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.26batch/s, loss=2.01965]\n",
      "Epoch 684/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.28batch/s, loss=2.49621]\n",
      "Epoch 685/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.62batch/s, loss=2.03628]\n",
      "Epoch 685/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1986.88batch/s, loss=2.51587]\n",
      "Epoch 686/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 119.52batch/s, loss=2.03369]\n",
      "Epoch 686/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 229.52batch/s, loss=2.52650]\n",
      "Epoch 687/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.27batch/s, loss=2.03719]\n",
      "Epoch 687/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 292.53batch/s, loss=2.49531]\n",
      "Epoch 688/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.66batch/s, loss=2.02735]\n",
      "Epoch 688/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 310.46batch/s, loss=2.50917]\n",
      "Epoch 689/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 196.81batch/s, loss=2.01323]\n",
      "Epoch 689/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.08batch/s, loss=2.51051]\n",
      "Epoch 690/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.95batch/s, loss=2.03494]\n",
      "Epoch 690/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 500.04batch/s, loss=2.53446]\n",
      "Epoch 691/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 249.86batch/s, loss=2.03257]\n",
      "Epoch 691/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.49191]\n",
      "Epoch 692/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 103.68batch/s, loss=2.03232]\n",
      "Epoch 692/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 397.90batch/s, loss=2.49640]\n",
      "Epoch 693/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.99batch/s, loss=2.01386]\n",
      "Epoch 693/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50955]\n",
      "Epoch 694/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 111.65batch/s, loss=2.02756]\n",
      "Epoch 694/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 181.03batch/s, loss=2.52789]\n",
      "Epoch 695/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 131.67batch/s, loss=2.03038]\n",
      "Epoch 695/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 346.18batch/s, loss=2.48461]\n",
      "Epoch 696/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.24batch/s, loss=2.03679]\n",
      "Epoch 696/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.69batch/s, loss=2.49805]\n",
      "Epoch 697/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.50batch/s, loss=2.02189]\n",
      "Epoch 697/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 477.77batch/s, loss=2.51875]\n",
      "Epoch 698/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.55batch/s, loss=2.02749]\n",
      "Epoch 698/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.72batch/s, loss=2.50556]\n",
      "Epoch 699/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.43batch/s, loss=2.02942]\n",
      "Epoch 699/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 357.94batch/s, loss=2.48389]\n",
      "Epoch 700/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.46batch/s, loss=2.02354]\n",
      "Epoch 700/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 407.93batch/s, loss=2.50109]\n",
      "Epoch 701/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.97batch/s, loss=2.03095]\n",
      "Epoch 701/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.17batch/s, loss=2.53844]\n",
      "Epoch 702/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.07batch/s, loss=2.02036]\n",
      "Epoch 702/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.86batch/s, loss=2.51209]\n",
      "Epoch 703/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.27batch/s, loss=2.00567]\n",
      "Epoch 703/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 263.43batch/s, loss=2.51050]\n",
      "Epoch 704/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.92batch/s, loss=2.03624]\n",
      "Epoch 704/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 456.00batch/s, loss=2.48308]\n",
      "Epoch 705/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.06batch/s, loss=2.00357]\n",
      "Epoch 705/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.80batch/s, loss=2.52261]\n",
      "Epoch 706/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 201.38batch/s, loss=2.01876]\n",
      "Epoch 706/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.30batch/s, loss=2.50662]\n",
      "Epoch 707/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.15batch/s, loss=2.02554]\n",
      "Epoch 707/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 209.75batch/s, loss=2.52434]\n",
      "Epoch 708/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 141.34batch/s, loss=2.03015]\n",
      "Epoch 708/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 663.76batch/s, loss=2.48422]\n",
      "Epoch 709/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.93batch/s, loss=2.04681]\n",
      "Epoch 709/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.49batch/s, loss=2.51780]\n",
      "Epoch 710/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 115.31batch/s, loss=2.04321]\n",
      "Epoch 710/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 226.93batch/s, loss=2.49678]\n",
      "Epoch 711/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.69batch/s, loss=2.02042]\n",
      "Epoch 711/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 389.23batch/s, loss=2.50276]\n",
      "Epoch 712/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.82batch/s, loss=2.03174]\n",
      "Epoch 712/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 291.88batch/s, loss=2.52562]\n",
      "Epoch 713/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.29batch/s, loss=2.02543]\n",
      "Epoch 713/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 442.62batch/s, loss=2.50514]\n",
      "Epoch 714/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.48batch/s, loss=2.03685]\n",
      "Epoch 714/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 508.83batch/s, loss=2.52272]\n",
      "Epoch 715/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 300.67batch/s, loss=2.03677]\n",
      "Epoch 715/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 125.20batch/s, loss=2.52827]\n",
      "Epoch 716/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.96batch/s, loss=2.06225]\n",
      "Epoch 716/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 269.75batch/s, loss=2.53412]\n",
      "Epoch 717/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.20batch/s, loss=2.04571]\n",
      "Epoch 717/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.29batch/s, loss=2.54700]\n",
      "Epoch 718/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.84batch/s, loss=2.02812]\n",
      "Epoch 718/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.60batch/s, loss=2.53848]\n",
      "Epoch 719/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.69batch/s, loss=2.02625]\n",
      "Epoch 719/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 500.10batch/s, loss=2.51737]\n",
      "Epoch 720/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.68batch/s, loss=2.03805]\n",
      "Epoch 720/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 316.29batch/s, loss=2.53159]\n",
      "Epoch 721/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.72batch/s, loss=2.05048]\n",
      "Epoch 721/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 186.05batch/s, loss=2.56107]\n",
      "Epoch 722/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 147.89batch/s, loss=2.04762]\n",
      "Epoch 722/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 388.40batch/s, loss=2.52729]\n",
      "Epoch 723/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 344.50batch/s, loss=2.04109]\n",
      "Epoch 723/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 127.75batch/s, loss=2.50150]\n",
      "Epoch 724/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 133.07batch/s, loss=2.02083]\n",
      "Epoch 724/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 409.32batch/s, loss=2.50077]\n",
      "Epoch 725/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.64batch/s, loss=2.03152]\n",
      "Epoch 725/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 311.71batch/s, loss=2.52332]\n",
      "Epoch 726/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.40batch/s, loss=2.02612]\n",
      "Epoch 726/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 466.45batch/s, loss=2.54319]\n",
      "Epoch 727/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.51batch/s, loss=2.04035]\n",
      "Epoch 727/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.15batch/s, loss=2.51847]\n",
      "Epoch 728/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.27batch/s, loss=2.03468]\n",
      "Epoch 728/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.61batch/s, loss=2.50566]\n",
      "Epoch 729/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.25batch/s, loss=2.04409]\n",
      "Epoch 729/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 399.04batch/s, loss=2.51225]\n",
      "Epoch 730/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.52batch/s, loss=2.03811]\n",
      "Epoch 730/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 318.28batch/s, loss=2.52013]\n",
      "Epoch 731/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.81batch/s, loss=2.01877]\n",
      "Epoch 731/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 477.82batch/s, loss=2.51082]\n",
      "Epoch 732/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 127.47batch/s, loss=2.04397]\n",
      "Epoch 732/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 175.09batch/s, loss=2.49991]\n",
      "Epoch 733/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 145.56batch/s, loss=2.01220]\n",
      "Epoch 733/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 472.97batch/s, loss=2.50532]\n",
      "Epoch 734/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.85batch/s, loss=2.02240]\n",
      "Epoch 734/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 435.64batch/s, loss=2.51146]\n",
      "Epoch 735/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.13batch/s, loss=2.03053]\n",
      "Epoch 735/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.43batch/s, loss=2.52720]\n",
      "Epoch 736/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.09batch/s, loss=2.04263]\n",
      "Epoch 736/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 355.45batch/s, loss=2.53324]\n",
      "Epoch 737/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.76batch/s, loss=2.04935]\n",
      "Epoch 737/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 315.29batch/s, loss=2.50102]\n",
      "Epoch 738/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.30batch/s, loss=2.03377]\n",
      "Epoch 738/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 306.27batch/s, loss=2.52228]\n",
      "Epoch 739/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.05batch/s, loss=2.04802]\n",
      "Epoch 739/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 485.00batch/s, loss=2.49296]\n",
      "Epoch 740/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 215.88batch/s, loss=2.00823]\n",
      "Epoch 740/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 305.33batch/s, loss=2.50610]\n",
      "Epoch 741/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.87batch/s, loss=2.02153]\n",
      "Epoch 741/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.91batch/s, loss=2.49142]\n",
      "Epoch 742/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 222.49batch/s, loss=2.04597]\n",
      "Epoch 742/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.52104]\n",
      "Epoch 743/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.93batch/s, loss=2.02411]\n",
      "Epoch 743/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50588]\n",
      "Epoch 744/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.65batch/s, loss=2.01853]\n",
      "Epoch 744/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.68batch/s, loss=2.49586]\n",
      "Epoch 745/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.64batch/s, loss=2.03447]\n",
      "Epoch 745/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.25batch/s, loss=2.51602]\n",
      "Epoch 746/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 478.26batch/s, loss=2.04316]\n",
      "Epoch 746/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 744.07batch/s, loss=2.51958]\n",
      "Epoch 747/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 105.16batch/s, loss=2.02762]\n",
      "Epoch 747/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 199.96batch/s, loss=2.49666]\n",
      "Epoch 748/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 128.89batch/s, loss=2.01448]\n",
      "Epoch 748/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.78batch/s, loss=2.48456]\n",
      "Epoch 749/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.05batch/s, loss=2.03473]\n",
      "Epoch 749/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.30batch/s, loss=2.52847]\n",
      "Epoch 750/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.53batch/s, loss=2.05365]\n",
      "Epoch 750/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 322.42batch/s, loss=2.51485]\n",
      "Epoch 751/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.56batch/s, loss=2.03021]\n",
      "Epoch 751/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 328.63batch/s, loss=2.48985]\n",
      "Epoch 752/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.52batch/s, loss=2.04539]\n",
      "Epoch 752/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.08batch/s, loss=2.52996]\n",
      "Epoch 753/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.72batch/s, loss=2.01436]\n",
      "Epoch 753/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 449.79batch/s, loss=2.50631]\n",
      "Epoch 754/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.74batch/s, loss=2.00768]\n",
      "Epoch 754/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 376.71batch/s, loss=2.53724]\n",
      "Epoch 755/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.57batch/s, loss=2.02983]\n",
      "Epoch 755/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.60batch/s, loss=2.50556]\n",
      "Epoch 756/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.48batch/s, loss=2.04041]\n",
      "Epoch 756/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.13batch/s, loss=2.53615]\n",
      "Epoch 757/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 154.41batch/s, loss=2.04734]\n",
      "Epoch 757/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 199.56batch/s, loss=2.49942]\n",
      "Epoch 758/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 140.04batch/s, loss=2.04212]\n",
      "Epoch 758/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 274.16batch/s, loss=2.51612]\n",
      "Epoch 759/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 126.38batch/s, loss=2.02637]\n",
      "Epoch 759/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 305.84batch/s, loss=2.52804]\n",
      "Epoch 760/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.11batch/s, loss=2.04439]\n",
      "Epoch 760/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 436.91batch/s, loss=2.50916]\n",
      "Epoch 761/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 124.31batch/s, loss=2.02050]\n",
      "Epoch 761/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.20batch/s, loss=2.51406]\n",
      "Epoch 762/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.53batch/s, loss=2.01434]\n",
      "Epoch 762/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.49279]\n",
      "Epoch 763/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.33batch/s, loss=2.01180]\n",
      "Epoch 763/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 243.15batch/s, loss=2.51011]\n",
      "Epoch 764/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.27batch/s, loss=2.01912]\n",
      "Epoch 764/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 382.20batch/s, loss=2.50465]\n",
      "Epoch 765/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.56batch/s, loss=2.03208]\n",
      "Epoch 765/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 419.35batch/s, loss=2.51221]\n",
      "Epoch 766/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.73batch/s, loss=2.03263]\n",
      "Epoch 766/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 470.32batch/s, loss=2.51449]\n",
      "Epoch 767/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.92batch/s, loss=2.03128]\n",
      "Epoch 767/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 391.59batch/s, loss=2.48541]\n",
      "Epoch 768/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.22batch/s, loss=2.00891]\n",
      "Epoch 768/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 336.03batch/s, loss=2.48843]\n",
      "Epoch 769/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.15batch/s, loss=2.01633]\n",
      "Epoch 769/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 417.05batch/s, loss=2.51392]\n",
      "Epoch 770/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.76batch/s, loss=2.02315]\n",
      "Epoch 770/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 515.08batch/s, loss=2.49531]\n",
      "Epoch 771/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.77batch/s, loss=2.02498]\n",
      "Epoch 771/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 229.71batch/s, loss=2.47955]\n",
      "Epoch 772/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 155.98batch/s, loss=2.02385]\n",
      "Epoch 772/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 397.64batch/s, loss=2.50642]\n",
      "Epoch 773/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 149.72batch/s, loss=2.04811]\n",
      "Epoch 773/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.28batch/s, loss=2.59537]\n",
      "Epoch 774/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.21batch/s, loss=2.01204]\n",
      "Epoch 774/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 134.79batch/s, loss=2.50280]\n",
      "Epoch 775/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 136.93batch/s, loss=2.05572]\n",
      "Epoch 775/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 228.00batch/s, loss=2.47916]\n",
      "Epoch 776/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 117.22batch/s, loss=2.01606]\n",
      "Epoch 776/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 363.14batch/s, loss=2.52617]\n",
      "Epoch 777/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.26batch/s, loss=2.00584]\n",
      "Epoch 777/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 291.72batch/s, loss=2.53296]\n",
      "Epoch 778/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 134.14batch/s, loss=2.04622]\n",
      "Epoch 778/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 249.94batch/s, loss=2.51147]\n",
      "Epoch 779/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 142.66batch/s, loss=2.01456]\n",
      "Epoch 779/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 238.04batch/s, loss=2.48688]\n",
      "Epoch 780/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.69batch/s, loss=2.03245]\n",
      "Epoch 780/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 462.28batch/s, loss=2.52384]\n",
      "Epoch 781/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.21batch/s, loss=2.04790]\n",
      "Epoch 781/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.85batch/s, loss=2.49911]\n",
      "Epoch 782/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 186.81batch/s, loss=2.01715]\n",
      "Epoch 782/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 548.42batch/s, loss=2.52801]\n",
      "Epoch 783/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.24batch/s, loss=2.03195]\n",
      "Epoch 783/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 809.55batch/s, loss=2.50257]\n",
      "Epoch 784/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.55batch/s, loss=2.03048]\n",
      "Epoch 784/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.55batch/s, loss=2.49068]\n",
      "Epoch 785/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.04batch/s, loss=2.03112]\n",
      "Epoch 785/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 385.22batch/s, loss=2.51595]\n",
      "Epoch 786/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.83batch/s, loss=2.01763]\n",
      "Epoch 786/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 486.58batch/s, loss=2.53607]\n",
      "Epoch 787/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.96batch/s, loss=2.04752]\n",
      "Epoch 787/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 500.04batch/s, loss=2.51159]\n",
      "Epoch 788/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.12batch/s, loss=2.07368]\n",
      "Epoch 788/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.56batch/s, loss=2.52869]\n",
      "Epoch 789/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.66batch/s, loss=2.03630]\n",
      "Epoch 789/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 493.80batch/s, loss=2.52521]\n",
      "Epoch 790/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 278.84batch/s, loss=2.01873]\n",
      "Epoch 790/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 487.26batch/s, loss=2.52951]\n",
      "Epoch 791/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.42batch/s, loss=2.04080]\n",
      "Epoch 791/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.90batch/s, loss=2.50771]\n",
      "Epoch 792/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.38batch/s, loss=2.01556]\n",
      "Epoch 792/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 493.10batch/s, loss=2.50294]\n",
      "Epoch 793/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 131.81batch/s, loss=2.01105]\n",
      "Epoch 793/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 268.40batch/s, loss=2.50538]\n",
      "Epoch 794/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.15batch/s, loss=2.02170]\n",
      "Epoch 794/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 477.98batch/s, loss=2.52429]\n",
      "Epoch 795/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 159.28batch/s, loss=2.00354]\n",
      "Epoch 795/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 440.44batch/s, loss=2.49634]\n",
      "Epoch 796/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.47batch/s, loss=2.04843]\n",
      "Epoch 796/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 495.55batch/s, loss=2.49453]\n",
      "Epoch 797/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.66batch/s, loss=2.01622]\n",
      "Epoch 797/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 489.87batch/s, loss=2.51746]\n",
      "Epoch 798/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.44batch/s, loss=2.01798]\n",
      "Epoch 798/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 394.76batch/s, loss=2.52944]\n",
      "Epoch 799/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.16batch/s, loss=2.02403]\n",
      "Epoch 799/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 996.98batch/s, loss=2.50767]\n",
      "Epoch 800/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.96batch/s, loss=2.01503]\n",
      "Epoch 800/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.51602]\n",
      "Epoch 801/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 206.66batch/s, loss=2.01700]\n",
      "Epoch 801/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 472.33batch/s, loss=2.54685]\n",
      "Epoch 802/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.77batch/s, loss=2.04683]\n",
      "Epoch 802/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.37batch/s, loss=2.50402]\n",
      "Epoch 803/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.27batch/s, loss=2.00661]\n",
      "Epoch 803/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 364.53batch/s, loss=2.53247]\n",
      "Epoch 804/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.13batch/s, loss=2.01299]\n",
      "Epoch 804/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 296.75batch/s, loss=2.50427]\n",
      "Epoch 805/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 198.05batch/s, loss=2.00772]\n",
      "Epoch 805/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 481.83batch/s, loss=2.51767]\n",
      "Epoch 806/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.01batch/s, loss=2.01204]\n",
      "Epoch 806/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 543.59batch/s, loss=2.51015]\n",
      "Epoch 807/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 178.80batch/s, loss=2.01239]\n",
      "Epoch 807/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 452.36batch/s, loss=2.51910]\n",
      "Epoch 808/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 144.83batch/s, loss=2.01612]\n",
      "Epoch 808/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50964]\n",
      "Epoch 809/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.73batch/s, loss=2.00753]\n",
      "Epoch 809/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 395.06batch/s, loss=2.50127]\n",
      "Epoch 810/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 267.44batch/s, loss=2.03524]\n",
      "Epoch 810/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 439.84batch/s, loss=2.58520]\n",
      "Epoch 811/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 160.20batch/s, loss=2.12311]\n",
      "Epoch 811/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 122.37batch/s, loss=2.56466]\n",
      "Epoch 812/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 159.55batch/s, loss=2.10484]\n",
      "Epoch 812/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.28batch/s, loss=2.56174]\n",
      "Epoch 813/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.80batch/s, loss=2.06997]\n",
      "Epoch 813/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.55087]\n",
      "Epoch 814/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 230.26batch/s, loss=2.08281]\n",
      "Epoch 814/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 127.58batch/s, loss=2.56250]\n",
      "Epoch 815/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 266.33batch/s, loss=2.03477]\n",
      "Epoch 815/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.54894]\n",
      "Epoch 816/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.49batch/s, loss=2.05268]\n",
      "Epoch 816/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.80batch/s, loss=2.52252]\n",
      "Epoch 817/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.23batch/s, loss=2.06077]\n",
      "Epoch 817/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.78batch/s, loss=2.52201]\n",
      "Epoch 818/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.07batch/s, loss=2.00401]\n",
      "Epoch 818/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 896.41batch/s, loss=2.57117]\n",
      "Epoch 819/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.01batch/s, loss=2.01013]\n",
      "Epoch 819/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 295.39batch/s, loss=2.51568]\n",
      "Epoch 820/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.42batch/s, loss=2.01820]\n",
      "Epoch 820/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 382.10batch/s, loss=2.48138]\n",
      "Epoch 821/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 275.04batch/s, loss=2.02275]\n",
      "Epoch 821/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 156.08batch/s, loss=2.50402]\n",
      "Epoch 822/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.76batch/s, loss=2.00762]\n",
      "Epoch 822/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 526.26batch/s, loss=2.52561]\n",
      "Epoch 823/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.76batch/s, loss=2.01142]\n",
      "Epoch 823/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 364.12batch/s, loss=2.49713]\n",
      "Epoch 824/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.54batch/s, loss=2.00972]\n",
      "Epoch 824/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 568.49batch/s, loss=2.49838]\n",
      "Epoch 825/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.00batch/s, loss=2.01117]\n",
      "Epoch 825/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 296.73batch/s, loss=2.53026]\n",
      "Epoch 826/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.41batch/s, loss=2.00326]\n",
      "Epoch 826/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.91batch/s, loss=2.53306]\n",
      "Epoch 827/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.52batch/s, loss=2.03100]\n",
      "Epoch 827/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.02batch/s, loss=2.50505]\n",
      "Epoch 828/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.59batch/s, loss=2.01138]\n",
      "Epoch 828/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 481.27batch/s, loss=2.47309]\n",
      "Epoch 829/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 138.86batch/s, loss=2.03067]\n",
      "Epoch 829/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 193.96batch/s, loss=2.50207]\n",
      "Epoch 830/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 121.10batch/s, loss=2.03521]\n",
      "Epoch 830/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.12batch/s, loss=2.57763]\n",
      "Epoch 831/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.01batch/s, loss=2.00123]\n",
      "Epoch 831/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.49batch/s, loss=2.49147]\n",
      "Epoch 832/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.83batch/s, loss=2.00331]\n",
      "Epoch 832/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 398.55batch/s, loss=2.47908]\n",
      "Epoch 833/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.04batch/s, loss=2.00626]\n",
      "Epoch 833/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.14batch/s, loss=2.52201]\n",
      "Epoch 834/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.12batch/s, loss=2.00914]\n",
      "Epoch 834/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 613.02batch/s, loss=2.53624]\n",
      "Epoch 835/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.75batch/s, loss=2.02226]\n",
      "Epoch 835/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 663.87batch/s, loss=2.49625]\n",
      "Epoch 836/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 175.66batch/s, loss=2.02434]\n",
      "Epoch 836/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 822.90batch/s, loss=2.48710]\n",
      "Epoch 837/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.44batch/s, loss=2.01970]\n",
      "Epoch 837/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 479.79batch/s, loss=2.52347]\n",
      "Epoch 838/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 143.89batch/s, loss=2.01356]\n",
      "Epoch 838/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 422.77batch/s, loss=2.50856]\n",
      "Epoch 839/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.32batch/s, loss=2.02063]\n",
      "Epoch 839/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 455.01batch/s, loss=2.49624]\n",
      "Epoch 840/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 340.31batch/s, loss=1.97922]\n",
      "Epoch 840/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 760.39batch/s, loss=2.48437]\n",
      "Epoch 841/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.10batch/s, loss=2.00898]\n",
      "Epoch 841/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.14batch/s, loss=2.48984]\n",
      "Epoch 842/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.00batch/s, loss=2.04089]\n",
      "Epoch 842/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.66batch/s, loss=2.52188]\n",
      "Epoch 843/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.64batch/s, loss=2.01708]\n",
      "Epoch 843/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 454.82batch/s, loss=2.54835]\n",
      "Epoch 844/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.66batch/s, loss=2.02518]\n",
      "Epoch 844/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 277.33batch/s, loss=2.49489]\n",
      "Epoch 845/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 122.12batch/s, loss=2.00353]\n",
      "Epoch 845/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 320.98batch/s, loss=2.49944]\n",
      "Epoch 846/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 146.44batch/s, loss=2.00359]\n",
      "Epoch 846/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 406.23batch/s, loss=2.52388]\n",
      "Epoch 847/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 151.01batch/s, loss=2.01044]\n",
      "Epoch 847/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 619.09batch/s, loss=2.52365]\n",
      "Epoch 848/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 217.01batch/s, loss=2.01356]\n",
      "Epoch 848/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.84batch/s, loss=2.51165]\n",
      "Epoch 849/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.46batch/s, loss=2.02681]\n",
      "Epoch 849/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 454.86batch/s, loss=2.52172]\n",
      "Epoch 850/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 213.89batch/s, loss=2.03409]\n",
      "Epoch 850/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.07batch/s, loss=2.52619]\n",
      "Epoch 851/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 324.08batch/s, loss=2.02861]\n",
      "Epoch 851/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 327.32batch/s, loss=2.50930]\n",
      "Epoch 852/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.46batch/s, loss=2.03834]\n",
      "Epoch 852/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 436.04batch/s, loss=2.52838]\n",
      "Epoch 853/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.80batch/s, loss=2.02876]\n",
      "Epoch 853/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 372.10batch/s, loss=2.52797]\n",
      "Epoch 854/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.18batch/s, loss=2.04071]\n",
      "Epoch 854/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.14batch/s, loss=2.51694]\n",
      "Epoch 855/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.41batch/s, loss=2.06234]\n",
      "Epoch 855/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 410.40batch/s, loss=2.48753]\n",
      "Epoch 856/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.09batch/s, loss=2.07201]\n",
      "Epoch 856/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 500.04batch/s, loss=2.56830]\n",
      "Epoch 857/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.36batch/s, loss=2.05268]\n",
      "Epoch 857/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.86batch/s, loss=2.51782]\n",
      "Epoch 858/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.65batch/s, loss=2.01966]\n",
      "Epoch 858/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 500.45batch/s, loss=2.51444]\n",
      "Epoch 859/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.08batch/s, loss=2.01101]\n",
      "Epoch 859/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.27batch/s, loss=2.53470]\n",
      "Epoch 860/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.23batch/s, loss=2.02417]\n",
      "Epoch 860/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.80batch/s, loss=2.51779]\n",
      "Epoch 861/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.65batch/s, loss=2.01694]\n",
      "Epoch 861/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.98batch/s, loss=2.55516]\n",
      "Epoch 862/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.18batch/s, loss=2.01107]\n",
      "Epoch 862/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.98batch/s, loss=2.50443]\n",
      "Epoch 863/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.74batch/s, loss=2.01143]\n",
      "Epoch 863/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.30batch/s, loss=2.52884]\n",
      "Epoch 864/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 149.59batch/s, loss=2.04955]\n",
      "Epoch 864/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 485.34batch/s, loss=2.49978]\n",
      "Epoch 865/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 159.06batch/s, loss=2.01737]\n",
      "Epoch 865/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 284.59batch/s, loss=2.54393]\n",
      "Epoch 866/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 186.47batch/s, loss=2.02567]\n",
      "Epoch 866/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 356.11batch/s, loss=2.51939]\n",
      "Epoch 867/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.83batch/s, loss=2.04637]\n",
      "Epoch 867/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 451.68batch/s, loss=2.52683]\n",
      "Epoch 868/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.48batch/s, loss=2.05153]\n",
      "Epoch 868/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 264.52batch/s, loss=2.53578]\n",
      "Epoch 869/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.08batch/s, loss=2.06437]\n",
      "Epoch 869/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 324.16batch/s, loss=2.57432]\n",
      "Epoch 870/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 197.01batch/s, loss=2.07243]\n",
      "Epoch 870/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 540.36batch/s, loss=2.52800]\n",
      "Epoch 871/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.04batch/s, loss=2.03023]\n",
      "Epoch 871/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 233.95batch/s, loss=2.53240]\n",
      "Epoch 872/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 174.27batch/s, loss=2.02049]\n",
      "Epoch 872/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 494.73batch/s, loss=2.56695]\n",
      "Epoch 873/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 266.78batch/s, loss=2.04270]\n",
      "Epoch 873/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.52300]\n",
      "Epoch 874/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 149.06batch/s, loss=2.04182]\n",
      "Epoch 874/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 391.95batch/s, loss=2.50925]\n",
      "Epoch 875/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 128.12batch/s, loss=2.01394]\n",
      "Epoch 875/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 413.60batch/s, loss=2.51610]\n",
      "Epoch 876/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.16batch/s, loss=2.03671]\n",
      "Epoch 876/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 434.06batch/s, loss=2.54615]\n",
      "Epoch 877/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.72batch/s, loss=2.02799]\n",
      "Epoch 877/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 311.33batch/s, loss=2.51647]\n",
      "Epoch 878/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.83batch/s, loss=2.00848]\n",
      "Epoch 878/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 491.14batch/s, loss=2.49366]\n",
      "Epoch 879/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.40batch/s, loss=2.00643]\n",
      "Epoch 879/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 399.04batch/s, loss=2.50944]\n",
      "Epoch 880/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.67batch/s, loss=2.00955]\n",
      "Epoch 880/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 800.75batch/s, loss=2.49671]\n",
      "Epoch 881/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 190.71batch/s, loss=1.98647]\n",
      "Epoch 881/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 212.54batch/s, loss=2.51794]\n",
      "Epoch 882/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 163.24batch/s, loss=2.01599]\n",
      "Epoch 882/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 411.45batch/s, loss=2.50458]\n",
      "Epoch 883/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 138.58batch/s, loss=2.00883]\n",
      "Epoch 883/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.43batch/s, loss=2.52069]\n",
      "Epoch 884/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.41batch/s, loss=2.04368]\n",
      "Epoch 884/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 327.07batch/s, loss=2.50244]\n",
      "Epoch 885/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 172.34batch/s, loss=2.03126]\n",
      "Epoch 885/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 457.64batch/s, loss=2.53510]\n",
      "Epoch 886/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 180.38batch/s, loss=2.03328]\n",
      "Epoch 886/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 434.42batch/s, loss=2.54137]\n",
      "Epoch 887/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.26batch/s, loss=2.01825]\n",
      "Epoch 887/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 584.49batch/s, loss=2.52450]\n",
      "Epoch 888/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 184.09batch/s, loss=2.02676]\n",
      "Epoch 888/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 536.70batch/s, loss=2.54450]\n",
      "Epoch 889/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.32batch/s, loss=2.04422]\n",
      "Epoch 889/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 381.16batch/s, loss=2.52950]\n",
      "Epoch 890/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.81batch/s, loss=2.00005]\n",
      "Epoch 890/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 255.78batch/s, loss=2.48831]\n",
      "Epoch 891/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 200.98batch/s, loss=2.02286]\n",
      "Epoch 891/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 644.48batch/s, loss=2.49380]\n",
      "Epoch 892/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 291.14batch/s, loss=2.00786]\n",
      "Epoch 892/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 121.39batch/s, loss=2.50571]\n",
      "Epoch 893/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 166.89batch/s, loss=2.01506]\n",
      "Epoch 893/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 364.03batch/s, loss=2.51114]\n",
      "Epoch 894/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 279.53batch/s, loss=2.01535]\n",
      "Epoch 894/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 127.46batch/s, loss=2.51636]\n",
      "Epoch 895/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 225.13batch/s, loss=2.03659]\n",
      "Epoch 895/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 151.14batch/s, loss=2.51960]\n",
      "Epoch 896/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 283.66batch/s, loss=2.01628]\n",
      "Epoch 896/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 616.90batch/s, loss=2.50429]\n",
      "Epoch 897/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 265.55batch/s, loss=2.02134]\n",
      "Epoch 897/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.04batch/s, loss=2.52501]\n",
      "Epoch 898/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 285.12batch/s, loss=2.00821]\n",
      "Epoch 898/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 369.35batch/s, loss=2.49470]\n",
      "Epoch 899/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 241.46batch/s, loss=1.99409]\n",
      "Epoch 899/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 487.88batch/s, loss=2.48973]\n",
      "Epoch 900/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 139.24batch/s, loss=1.99734]\n",
      "Epoch 900/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 313.45batch/s, loss=2.55518]\n",
      "Epoch 901/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.85batch/s, loss=2.04563]\n",
      "Epoch 901/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 311.22batch/s, loss=2.50200]\n",
      "Epoch 902/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 186.45batch/s, loss=2.00471]\n",
      "Epoch 902/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 430.36batch/s, loss=2.47943]\n",
      "Epoch 903/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.44batch/s, loss=2.00407]\n",
      "Epoch 903/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.51670]\n",
      "Epoch 904/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.23batch/s, loss=2.02112]\n",
      "Epoch 904/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 468.01batch/s, loss=2.52064]\n",
      "Epoch 905/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 206.67batch/s, loss=2.04119]\n",
      "Epoch 905/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.52220]\n",
      "Epoch 906/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 129.54batch/s, loss=2.04941]\n",
      "Epoch 906/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.48842]\n",
      "Epoch 907/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 129.97batch/s, loss=1.99162]\n",
      "Epoch 907/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50820]\n",
      "Epoch 908/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 131.44batch/s, loss=2.04328]\n",
      "Epoch 908/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 435.05batch/s, loss=2.50446]\n",
      "Epoch 909/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.59batch/s, loss=2.06677]\n",
      "Epoch 909/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 326.02batch/s, loss=2.54336]\n",
      "Epoch 910/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 185.06batch/s, loss=2.02910]\n",
      "Epoch 910/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.44batch/s, loss=2.51284]\n",
      "Epoch 911/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.63batch/s, loss=2.01807]\n",
      "Epoch 911/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.52676]\n",
      "Epoch 912/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 195.15batch/s, loss=2.01651]\n",
      "Epoch 912/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.20batch/s, loss=2.55028]\n",
      "Epoch 913/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 150.88batch/s, loss=2.04534]\n",
      "Epoch 913/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 587.27batch/s, loss=2.52712]\n",
      "Epoch 914/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.24batch/s, loss=2.06389]\n",
      "Epoch 914/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 209.39batch/s, loss=2.53167]\n",
      "Epoch 915/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.28batch/s, loss=2.05354]\n",
      "Epoch 915/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 787.96batch/s, loss=2.49442]\n",
      "Epoch 916/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 147.25batch/s, loss=2.03294]\n",
      "Epoch 916/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 134.88batch/s, loss=2.53007]\n",
      "Epoch 917/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.07batch/s, loss=2.01709]\n",
      "Epoch 917/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 615.00batch/s, loss=2.52610]\n",
      "Epoch 918/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 148.11batch/s, loss=2.03541]\n",
      "Epoch 918/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 236.31batch/s, loss=2.54207]\n",
      "Epoch 919/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.75batch/s, loss=2.01456]\n",
      "Epoch 919/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.84batch/s, loss=2.52516]\n",
      "Epoch 920/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 301.57batch/s, loss=2.01316]\n",
      "Epoch 920/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 540.57batch/s, loss=2.49095]\n",
      "Epoch 921/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 239.26batch/s, loss=2.01585]\n",
      "Epoch 921/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 330.78batch/s, loss=2.50619]\n",
      "Epoch 922/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 345.79batch/s, loss=1.98729]\n",
      "Epoch 922/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50371]\n",
      "Epoch 923/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 177.25batch/s, loss=2.01730]\n",
      "Epoch 923/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50660]\n",
      "Epoch 924/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 132.37batch/s, loss=1.99057]\n",
      "Epoch 924/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 277.47batch/s, loss=2.50118]\n",
      "Epoch 925/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 193.13batch/s, loss=2.00945]\n",
      "Epoch 925/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.49batch/s, loss=2.53503]\n",
      "Epoch 926/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 219.57batch/s, loss=2.04722]\n",
      "Epoch 926/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.25batch/s, loss=2.58060]\n",
      "Epoch 927/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 168.89batch/s, loss=2.03005]\n",
      "Epoch 927/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 397.49batch/s, loss=2.53586]\n",
      "Epoch 928/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 226.93batch/s, loss=2.04017]\n",
      "Epoch 928/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 436.27batch/s, loss=2.53524]\n",
      "Epoch 929/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.27batch/s, loss=2.02865]\n",
      "Epoch 929/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 470.58batch/s, loss=2.54781]\n",
      "Epoch 930/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 182.88batch/s, loss=2.01739]\n",
      "Epoch 930/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 321.21batch/s, loss=2.54858]\n",
      "Epoch 931/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 209.27batch/s, loss=2.04056]\n",
      "Epoch 931/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.84batch/s, loss=2.55473]\n",
      "Epoch 932/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 183.84batch/s, loss=2.07191]\n",
      "Epoch 932/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.30batch/s, loss=2.49989]\n",
      "Epoch 933/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 171.87batch/s, loss=2.05855]\n",
      "Epoch 933/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 298.68batch/s, loss=2.52782]\n",
      "Epoch 934/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.95batch/s, loss=2.03742]\n",
      "Epoch 934/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 400.60batch/s, loss=2.53565]\n",
      "Epoch 935/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 131.42batch/s, loss=2.01956]\n",
      "Epoch 935/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 306.02batch/s, loss=2.52924]\n",
      "Epoch 936/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 140.64batch/s, loss=2.02094]\n",
      "Epoch 936/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.43batch/s, loss=2.52363]\n",
      "Epoch 937/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.51batch/s, loss=2.02680]\n",
      "Epoch 937/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 367.41batch/s, loss=2.56991]\n",
      "Epoch 938/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.11batch/s, loss=2.04204]\n",
      "Epoch 938/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.83batch/s, loss=2.50125]\n",
      "Epoch 939/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 211.91batch/s, loss=2.01535]\n",
      "Epoch 939/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.98batch/s, loss=2.49113]\n",
      "Epoch 940/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 222.53batch/s, loss=2.02910]\n",
      "Epoch 940/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.78batch/s, loss=2.52742]\n",
      "Epoch 941/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 194.22batch/s, loss=2.00791]\n",
      "Epoch 941/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 488.51batch/s, loss=2.52131]\n",
      "Epoch 942/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 217.25batch/s, loss=2.03283]\n",
      "Epoch 942/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 329.53batch/s, loss=2.54999]\n",
      "Epoch 943/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.58batch/s, loss=2.03093]\n",
      "Epoch 943/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 256.08batch/s, loss=2.50362]\n",
      "Epoch 944/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 223.25batch/s, loss=2.03106]\n",
      "Epoch 944/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 453.44batch/s, loss=2.48047]\n",
      "Epoch 945/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 191.70batch/s, loss=2.01150]\n",
      "Epoch 945/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 479.90batch/s, loss=2.51696]\n",
      "Epoch 946/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 196.57batch/s, loss=2.01724]\n",
      "Epoch 946/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 333.01batch/s, loss=2.55269]\n",
      "Epoch 947/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 164.27batch/s, loss=2.04256]\n",
      "Epoch 947/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 493.22batch/s, loss=2.49415]\n",
      "Epoch 948/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 189.78batch/s, loss=2.00114]\n",
      "Epoch 948/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 825.65batch/s, loss=2.51421]\n",
      "Epoch 949/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 200.09batch/s, loss=2.03153]\n",
      "Epoch 949/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 497.84batch/s, loss=2.55426]\n",
      "Epoch 950/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 188.39batch/s, loss=2.04273]\n",
      "Epoch 950/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 406.23batch/s, loss=2.54211]\n",
      "Epoch 951/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 158.57batch/s, loss=2.02721]\n",
      "Epoch 951/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 350.99batch/s, loss=2.51955]\n",
      "Epoch 952/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 179.13batch/s, loss=2.02506]\n",
      "Epoch 952/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 2526.69batch/s, loss=2.55206]\n",
      "Epoch 953/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 205.99batch/s, loss=2.02370]\n",
      "Epoch 953/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 147.76batch/s, loss=2.50102]\n",
      "Epoch 954/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 181.07batch/s, loss=2.00851]\n",
      "Epoch 954/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 217.55batch/s, loss=2.52255]\n",
      "Epoch 955/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.82batch/s, loss=2.01712]\n",
      "Epoch 955/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 355.48batch/s, loss=2.55630]\n",
      "Epoch 956/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 165.24batch/s, loss=2.01052]\n",
      "Epoch 956/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 233.25batch/s, loss=2.54149]\n",
      "Epoch 957/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 161.85batch/s, loss=2.03568]\n",
      "Epoch 957/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 150.89batch/s, loss=2.49829]\n",
      "Epoch 958/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 255.81batch/s, loss=1.99820]\n",
      "Epoch 958/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 124.08batch/s, loss=2.49470]\n",
      "Epoch 959/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 186.21batch/s, loss=1.99330]\n",
      "Epoch 959/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.31batch/s, loss=2.55298]\n",
      "Epoch 960/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 208.07batch/s, loss=2.03234]\n",
      "Epoch 960/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 403.69batch/s, loss=2.50536]\n",
      "Epoch 961/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 214.64batch/s, loss=2.00211]\n",
      "Epoch 961/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 828.42batch/s, loss=2.48928]\n",
      "Epoch 962/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 250.44batch/s, loss=2.03184]\n",
      "Epoch 962/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 144.01batch/s, loss=2.48824]\n",
      "Epoch 963/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 225.93batch/s, loss=2.03933]\n",
      "Epoch 963/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 156.97batch/s, loss=2.53246]\n",
      "Epoch 964/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 214.72batch/s, loss=2.05339]\n",
      "Epoch 964/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 407.17batch/s, loss=2.53890]\n",
      "Epoch 965/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.45batch/s, loss=2.03378]\n",
      "Epoch 965/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.98batch/s, loss=2.50256]\n",
      "Epoch 966/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 176.39batch/s, loss=2.03393]\n",
      "Epoch 966/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 382.20batch/s, loss=2.57004]\n",
      "Epoch 967/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 173.64batch/s, loss=2.03179]\n",
      "Epoch 967/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.54batch/s, loss=2.54248]\n",
      "Epoch 968/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 170.46batch/s, loss=2.03431]\n",
      "Epoch 968/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 160.57batch/s, loss=2.54443]\n",
      "Epoch 969/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 153.28batch/s, loss=2.01316]\n",
      "Epoch 969/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.55batch/s, loss=2.55295]\n",
      "Epoch 970/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 206.04batch/s, loss=2.03338]\n",
      "Epoch 970/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 364.63batch/s, loss=2.52093]\n",
      "Epoch 971/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 169.87batch/s, loss=1.99850]\n",
      "Epoch 971/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 399.53batch/s, loss=2.50485]\n",
      "Epoch 972/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 110.95batch/s, loss=1.99649]\n",
      "Epoch 972/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 316.24batch/s, loss=2.48850]\n",
      "Epoch 973/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 134.07batch/s, loss=1.97465]\n",
      "Epoch 973/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 493.16batch/s, loss=2.53595]\n",
      "Epoch 974/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 156.59batch/s, loss=1.98176]\n",
      "Epoch 974/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.52017]\n",
      "Epoch 975/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 226.09batch/s, loss=2.01468]\n",
      "Epoch 975/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 197.34batch/s, loss=2.48109]\n",
      "Epoch 976/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 200.02batch/s, loss=2.02741]\n",
      "Epoch 976/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 498.02batch/s, loss=2.52642]\n",
      "Epoch 977/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 216.35batch/s, loss=2.02425]\n",
      "Epoch 977/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.26batch/s, loss=2.53253]\n",
      "Epoch 978/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.15batch/s, loss=2.00312]\n",
      "Epoch 978/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.52028]\n",
      "Epoch 979/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 199.03batch/s, loss=2.00055]\n",
      "Epoch 979/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.47856]\n",
      "Epoch 980/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 137.62batch/s, loss=2.00707]\n",
      "Epoch 980/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 372.99batch/s, loss=2.53729]\n",
      "Epoch 981/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 143.13batch/s, loss=2.01700]\n",
      "Epoch 981/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 496.31batch/s, loss=2.49511]\n",
      "Epoch 982/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 187.30batch/s, loss=2.03970]\n",
      "Epoch 982/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.49397]\n",
      "Epoch 983/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 134.18batch/s, loss=2.02336]\n",
      "Epoch 983/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 332.59batch/s, loss=2.54731]\n",
      "Epoch 984/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 204.00batch/s, loss=2.01280]\n",
      "Epoch 984/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 852.15batch/s, loss=2.53998]\n",
      "Epoch 985/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 152.31batch/s, loss=2.00763]\n",
      "Epoch 985/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.50165]\n",
      "Epoch 986/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 131.09batch/s, loss=1.97008]\n",
      "Epoch 986/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 650.68batch/s, loss=2.50540]\n",
      "Epoch 987/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 142.81batch/s, loss=2.00299]\n",
      "Epoch 987/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 1986.88batch/s, loss=2.53852]\n",
      "Epoch 988/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 138.07batch/s, loss=2.05351]\n",
      "Epoch 988/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 499.56batch/s, loss=2.50618]\n",
      "Epoch 989/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 138.07batch/s, loss=2.03956]\n",
      "Epoch 989/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 272.71batch/s, loss=2.47213]\n",
      "Epoch 990/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 141.37batch/s, loss=2.00180]\n",
      "Epoch 990/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 697.89batch/s, loss=2.57452]\n",
      "Epoch 991/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 203.73batch/s, loss=2.02038]\n",
      "Epoch 991/1000 - Validation: 100%|██████████| 1/1 [00:00<?, ?batch/s, loss=2.54557]\n",
      "Epoch 992/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 240.71batch/s, loss=2.04403]\n",
      "Epoch 992/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 462.74batch/s, loss=2.55733]\n",
      "Epoch 993/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 202.24batch/s, loss=2.04272]\n",
      "Epoch 993/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.64batch/s, loss=2.50434]\n",
      "Epoch 994/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 274.48batch/s, loss=2.02262]\n",
      "Epoch 994/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 331.07batch/s, loss=2.54952]\n",
      "Epoch 995/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 167.74batch/s, loss=2.03834]\n",
      "Epoch 995/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 769.74batch/s, loss=2.56105]\n",
      "Epoch 996/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 239.28batch/s, loss=2.03177]\n",
      "Epoch 996/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 795.88batch/s, loss=2.50699]\n",
      "Epoch 997/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 192.11batch/s, loss=2.02075]\n",
      "Epoch 997/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 612.93batch/s, loss=2.53789]\n",
      "Epoch 998/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 214.23batch/s, loss=2.06514]\n",
      "Epoch 998/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 490.68batch/s, loss=2.62790]\n",
      "Epoch 999/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 288.19batch/s, loss=2.04557]\n",
      "Epoch 999/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 488.16batch/s, loss=2.51994]\n",
      "Epoch 1000/1000 - Training: 100%|██████████| 2/2 [00:00<00:00, 342.13batch/s, loss=2.03575]\n",
      "Epoch 1000/1000 - Validation: 100%|██████████| 1/1 [00:00<00:00, 121.11batch/s, loss=2.49249]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found at epoch 989 with validation loss: 2.47213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "lowest_val_loss = float('inf')  # Initialize with a large value\n",
    "best_epoch = 0\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Training', unit='batch') as t:\n",
    "        for batch in t:\n",
    "            input_data, _ = batch\n",
    "            input_data = input_data.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output_data = model(input_data)\n",
    "            loss = criterion(output_data, input_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            t.set_postfix(loss=f'{total_train_loss / len(train_loader):.5f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, desc=f'Epoch {epoch + 1}/{num_epochs} - Validation', unit='batch') as t:\n",
    "            for batch in t:\n",
    "                val_input_data, _ = batch\n",
    "                val_input_data = val_input_data.to(device)\n",
    "\n",
    "                val_output_data = model(val_input_data)\n",
    "                val_loss = criterion(val_output_data, val_input_data)\n",
    "                total_val_loss += val_loss.item()\n",
    "                t.set_postfix(loss=f'{total_val_loss / len(val_loader):.5f}')\n",
    "\n",
    "    # Save model if validation loss is the lowest\n",
    "    if total_val_loss < lowest_val_loss:\n",
    "        lowest_val_loss = total_val_loss\n",
    "        best_epoch = epoch + 1  # Epochs are 0-indexed, so add 1\n",
    "\n",
    "        # Save the model's state dictionary and other relevant information\n",
    "        checkpoint_path = 'best_model_checkpoint_wine.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lowest_val_loss': lowest_val_loss,\n",
    "        }, checkpoint_path)\n",
    "\n",
    "print(f\"Best model found at epoch {best_epoch} with validation loss: {lowest_val_loss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = 'best_model_checkpoint_wine.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model = Autoencoder(inputs_dim, n_bottleneck).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data=torch.FloatTensor(df.values).to(device)\n",
    "df_encoded=model.encoder(tensor_data)\n",
    "df_encoded_cpu = df_encoded.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "import umap.umap_ as umap\n",
    "df_umapped = umap.UMAP(n_components = n_bottleneck / 2, \n",
    "                           metric = \"euclidean\",\n",
    "                           n_neighbors = 50, \n",
    "                           min_dist = 0.0,\n",
    "                           random_state = 13).fit_transform(df_encoded_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.6511828899383545\n",
      "Davies-Bouldin Index: 0.45320982763178597\n",
      "Calinski-Harabasz Index: 809.8081017000421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Assuming you have your review_umapped data\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(df_umapped)\n",
    "\n",
    "# Silhouette Score\n",
    "silhouette_avg = silhouette_score(df_umapped, cluster_labels)\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n",
    "\n",
    "# Davies-Bouldin Index\n",
    "db_index = davies_bouldin_score(df_umapped, cluster_labels)\n",
    "print(f'Davies-Bouldin Index: {db_index}')\n",
    "\n",
    "# Calinski-Harabasz Index\n",
    "ch_index = calinski_harabasz_score(df_umapped, cluster_labels)\n",
    "print(f'Calinski-Harabasz Index: {ch_index}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
